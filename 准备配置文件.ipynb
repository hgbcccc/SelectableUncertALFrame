{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae89ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "import os\n",
    "\n",
    "# ç®€åŒ–çš„é…ç½®æ–‡ä»¶ä¿®æ”¹æ–¹æ³•\n",
    "def update_single_config(config_path):\n",
    "    \"\"\"ç›´æ¥é€šè¿‡cfgå±æ€§ä¿®æ”¹é…ç½®æ–‡ä»¶\"\"\"\n",
    "    # åŠ è½½é…ç½®æ–‡ä»¶\n",
    "    cfg = Config.fromfile(config_path)\n",
    "    \n",
    "    # ä»æ–‡ä»¶åæå–ä¿¡æ¯\n",
    "    filename = os.path.basename(config_path)\n",
    "    \n",
    "    # ç¡®å®šæ¨¡å‹ç±»å‹\n",
    "    if 'cascade-rcnn' in filename:\n",
    "        model_type = 'cascade'\n",
    "    elif 'faster-rcnn' in filename:\n",
    "        model_type = 'faster'\n",
    "    elif 'retinanet' in filename:\n",
    "        model_type = 'retinanet'\n",
    "    else:\n",
    "        model_type = 'cascade'\n",
    "    \n",
    "    # ç¡®å®šé‡‡æ ·æ–¹æ³•\n",
    "    sampling_methods = ['ssc', 'sor', 'random', 'entropy', 'mus_cdb', 'margin', 'least_confidence']\n",
    "    sampling_method = 'ssc'  # é»˜è®¤å€¼\n",
    "    for method in sampling_methods:\n",
    "        if method in filename:\n",
    "            sampling_method = method\n",
    "            break\n",
    "    \n",
    "    print(f\"æ›´æ–°é…ç½®: {filename} ({model_type}_{sampling_method})\")\n",
    "    \n",
    "    # æ„å»ºæ–°çš„æ•°æ®è·¯å¾„\n",
    "    data_root = f'data/ForestDamages/active_learning_{model_type}_{sampling_method}'\n",
    "    \n",
    "    # ç›´æ¥ä¿®æ”¹cfgçš„å±æ€§\n",
    "    # 1. ä¿®æ”¹æ•°æ®æ ¹ç›®å½•\n",
    "    cfg.data_root = data_root\n",
    "    \n",
    "    # 2. ä¿®æ”¹è®­ç»ƒæ•°æ®åŠ è½½å™¨è·¯å¾„\n",
    "    cfg.train_dataloader.dataset.data_root = data_root\n",
    "    cfg.train_dataloader.dataset.ann_file = f'{data_root}/annotations/instances_labeled_train.json'\n",
    "    cfg.train_dataloader.dataset.data_prefix.img = f'{data_root}/images_labeled_train'\n",
    "    \n",
    "    # 3. ä¿®æ”¹éªŒè¯æ•°æ®åŠ è½½å™¨è·¯å¾„  \n",
    "    cfg.val_dataloader.dataset.data_root = data_root\n",
    "    cfg.val_dataloader.dataset.ann_file = f'{data_root}/annotations/instances_labeled_val.json'\n",
    "    cfg.val_dataloader.dataset.data_prefix.img = f'{data_root}/images_labeled_val'\n",
    "    \n",
    "    # 4. ä¿®æ”¹éªŒè¯è¯„ä¼°å™¨è·¯å¾„\n",
    "    cfg.val_evaluator.ann_file = f'{data_root}/annotations/instances_labeled_val.json'\n",
    "    \n",
    "    # 5. ä¿®æ”¹active_learningé…ç½®è·¯å¾„\n",
    "    cfg.active_learning.data_root = data_root\n",
    "    cfg.active_learning.ann_file = f'{data_root}/annotations/instances_unlabeled.json'\n",
    "    cfg.active_learning.data_prefix.img = f'{data_root}/images_unlabeled'\n",
    "    cfg.active_learning.train_pool_cfg.data_root = data_root\n",
    "    \n",
    "    # 6. ç»Ÿä¸€batch_sizeè®¾ç½®ï¼ˆé‡è¦ï¼šç¡®ä¿ä¸åŒé‡‡æ ·ç­–ç•¥ä½¿ç”¨ç›¸åŒçš„batch sizeï¼‰\n",
    "    # è®­ç»ƒbatch size\n",
    "    cfg.train_dataloader.batch_size = 4  # ç»Ÿä¸€è®¾ç½®ä¸º4ï¼Œç¡®ä¿ä¸€è‡´æ€§\n",
    "    \n",
    "    # éªŒè¯batch size  \n",
    "    cfg.val_dataloader.batch_size = 4\n",
    "    \n",
    "    # ä¸»åŠ¨å­¦ä¹ æ¨ç†batch size\n",
    "    if hasattr(cfg, 'active_learning') and hasattr(cfg.active_learning, 'inference_options'):\n",
    "        cfg.active_learning.inference_options.batch_size = 8  # æ¨ç†å¯ä»¥ç¨å¤§ä¸€äº›\n",
    "    \n",
    "    # 7. è®¾ç½®å·¥ä½œç›®å½•\n",
    "    cfg.work_dir = f'work_dirs/{model_type}_{sampling_method}'\n",
    "    \n",
    "    # ä¿å­˜ä¿®æ”¹åçš„é…ç½®\n",
    "    cfg.dump(config_path)\n",
    "    print(f\"âœ“ å·²ä¿å­˜: {data_root}, batch_size=4 (ç»Ÿä¸€è®¾ç½®)\")\n",
    "\n",
    "# æ‰¹é‡æ›´æ–°æ‰€æœ‰é…ç½®æ–‡ä»¶\n",
    "config_dir = 'al_configs'\n",
    "config_files = []\n",
    "\n",
    "# æ”¶é›†æ‰€æœ‰é…ç½®æ–‡ä»¶\n",
    "for root, dirs, files in os.walk(config_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.py'):\n",
    "            config_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶\")\n",
    "\n",
    "# æ‰¹é‡æ›´æ–°\n",
    "for config_file in sorted(config_files):\n",
    "    try:\n",
    "        update_single_config(config_file)\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— æ›´æ–°å¤±è´¥ {config_file}: {e}\")\n",
    "\n",
    "print(\"æ‰¹é‡æ›´æ–°å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27166c6",
   "metadata": {},
   "source": [
    "### å‡†å¤‡é…ç½®æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸“é—¨ç”¨äºç»Ÿä¸€æ‰€æœ‰é…ç½®æ–‡ä»¶çš„batch_sizeè®¾ç½®\n",
    "def unify_batch_sizes(target_batch_size=4):\n",
    "    \"\"\"\n",
    "    ç»Ÿä¸€æ‰€æœ‰é…ç½®æ–‡ä»¶çš„batch_sizeï¼Œè§£å†³ä¸åŒé‡‡æ ·ç­–ç•¥æ€§èƒ½ä¸ä¸€è‡´çš„é—®é¢˜\n",
    "    \"\"\"\n",
    "    config_dir = 'al_configs'\n",
    "    config_files = []\n",
    "    \n",
    "    # æ”¶é›†æ‰€æœ‰é…ç½®æ–‡ä»¶\n",
    "    for root, dirs, files in os.walk(config_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                config_files.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f\"=== ç»Ÿä¸€batch_sizeè®¾ç½®ä¸º: {target_batch_size} ===\")\n",
    "    \n",
    "    for config_file in sorted(config_files):\n",
    "        try:\n",
    "            cfg = Config.fromfile(config_file)\n",
    "            \n",
    "            # æ£€æŸ¥å½“å‰çš„batch_sizeè®¾ç½®\n",
    "            train_bs = cfg.train_dataloader.batch_size\n",
    "            val_bs = cfg.val_dataloader.batch_size\n",
    "            \n",
    "            # ç»Ÿä¸€è®¾ç½®batch_size\n",
    "            cfg.train_dataloader.batch_size = target_batch_size\n",
    "            cfg.val_dataloader.batch_size = target_batch_size\n",
    "            \n",
    "            # å¦‚æœæœ‰ä¸»åŠ¨å­¦ä¹ æ¨ç†è®¾ç½®ï¼Œä¹Ÿç»Ÿä¸€\n",
    "            if hasattr(cfg, 'active_learning') and hasattr(cfg.active_learning, 'inference_options'):\n",
    "                old_inference_bs = cfg.active_learning.inference_options.batch_size\n",
    "                cfg.active_learning.inference_options.batch_size = target_batch_size * 2  # æ¨ç†å¯ä»¥ç¨å¤§\n",
    "                print(f\"{os.path.basename(config_file)}: train({train_bs}->{target_batch_size}), val({val_bs}->{target_batch_size}), inference({old_inference_bs}->{target_batch_size*2})\")\n",
    "            else:\n",
    "                print(f\"{os.path.basename(config_file)}: train({train_bs}->{target_batch_size}), val({val_bs}->{target_batch_size})\")\n",
    "            \n",
    "            # ä¿å­˜é…ç½®\n",
    "            cfg.dump(config_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— å¤„ç†å¤±è´¥ {config_file}: {e}\")\n",
    "    \n",
    "    print(\"=== batch_sizeç»Ÿä¸€å®Œæˆ ===\")\n",
    "\n",
    "# æ‰§è¡Œç»Ÿä¸€batch_sizeæ“ä½œ\n",
    "# unify_batch_sizes(4)  # å–æ¶ˆæ³¨é‡Šæ¥æ‰§è¡Œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è§£å†³mini-batchç»„æˆå·®å¼‚çš„æ ¸å¿ƒé—®é¢˜\n",
    "def fix_minibatch_consistency():\n",
    "    \"\"\"\n",
    "    è§£å†³ä¸åŒé‡‡æ ·ç­–ç•¥mini-batchç»„æˆä¸ä¸€è‡´çš„é—®é¢˜\n",
    "    \"\"\"\n",
    "    config_dir = 'al_configs'\n",
    "    config_files = []\n",
    "    \n",
    "    # æ”¶é›†æ‰€æœ‰é…ç½®æ–‡ä»¶\n",
    "    for root, dirs, files in os.walk(config_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                config_files.append(os.path.join(root, file))\n",
    "    \n",
    "    print(\"=== ä¿®å¤mini-batchä¸€è‡´æ€§é—®é¢˜ ===\")\n",
    "    \n",
    "    for config_file in sorted(config_files):\n",
    "        try:\n",
    "            cfg = Config.fromfile(config_file)\n",
    "            \n",
    "            filename = os.path.basename(config_file)\n",
    "            print(f\"å¤„ç†: {filename}\")\n",
    "            \n",
    "            # 1. å›ºå®šéšæœºç§å­ - ç¡®ä¿æ•°æ®åŠ è½½é¡ºåºä¸€è‡´\n",
    "            cfg.randomness = dict(\n",
    "                seed=42,                    # å›ºå®šç§å­\n",
    "                deterministic=True,         # ç¡®å®šæ€§è¡Œä¸º\n",
    "                diff_rank_seed=False        # ä¸åŒrankä½¿ç”¨ç›¸åŒç§å­\n",
    "            )\n",
    "            \n",
    "            # 2. ä¿®æ”¹æ•°æ®é‡‡æ ·å™¨ - ç¦ç”¨shuffleç¡®ä¿é¡ºåºä¸€è‡´\n",
    "            if hasattr(cfg, 'train_dataloader') and hasattr(cfg.train_dataloader, 'sampler'):\n",
    "                cfg.train_dataloader.sampler = dict(\n",
    "                    type='DefaultSampler', \n",
    "                    shuffle=False,          # ç¦ç”¨éšæœºæ‰“ä¹±\n",
    "                    seed=42                 # å›ºå®šç§å­\n",
    "                )\n",
    "            \n",
    "            # 3. ç¦ç”¨AspectRatioBatchSampler - é¿å…æŒ‰å®½é«˜æ¯”é‡æ–°ç»„åˆbatch\n",
    "            if hasattr(cfg, 'train_dataloader'):\n",
    "                cfg.train_dataloader.batch_sampler = None  # ä½¿ç”¨é»˜è®¤batché‡‡æ ·\n",
    "            \n",
    "            # 4. å›ºå®šæ•°æ®å¤„ç†pipelineä¸­çš„éšæœºæ€§\n",
    "            if hasattr(cfg, 'train_pipeline'):\n",
    "                for i, transform in enumerate(cfg.train_pipeline):\n",
    "                    if transform.get('type') == 'RandomFlip':\n",
    "                        # å¯ä»¥é€‰æ‹©å®Œå…¨ç¦ç”¨æˆ–å›ºå®šç§å­\n",
    "                        cfg.train_pipeline[i]['prob'] = 0.0  # ç¦ç”¨éšæœºç¿»è½¬\n",
    "                    elif transform.get('type') == 'PhotoMetricDistortion':\n",
    "                        # ç¦ç”¨é¢œè‰²å¢å¼ºçš„éšæœºæ€§\n",
    "                        cfg.train_pipeline[i] = dict(type='Identity')  # æ›¿æ¢ä¸ºæ— æ“ä½œ\n",
    "            \n",
    "            # 5. ç¡®ä¿éªŒè¯ä¹Ÿä½¿ç”¨ä¸€è‡´çš„è®¾ç½®\n",
    "            if hasattr(cfg, 'val_dataloader') and hasattr(cfg.val_dataloader, 'sampler'):\n",
    "                cfg.val_dataloader.sampler = dict(\n",
    "                    type='DefaultSampler',\n",
    "                    shuffle=False,\n",
    "                    seed=42\n",
    "                )\n",
    "            \n",
    "            print(f\"  âœ“ å·²å›ºå®šéšæœºç§å­å’Œé‡‡æ ·é¡ºåº\")\n",
    "            \n",
    "            # ä¿å­˜é…ç½®\n",
    "            cfg.dump(config_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— å¤„ç†å¤±è´¥ {config_file}: {e}\")\n",
    "    \n",
    "    print(\"=== mini-batchä¸€è‡´æ€§ä¿®å¤å®Œæˆ ===\")\n",
    "\n",
    "# é€‰æ‹©æ€§è§£å†³æ–¹æ¡ˆï¼šåªå›ºå®šç§å­ä½†ä¿ç•™æ•°æ®å¢å¼º\n",
    "def fix_seeds_only():\n",
    "    \"\"\"åªå›ºå®šéšæœºç§å­ï¼Œä¿æŒæ•°æ®å¢å¼ºçš„å¤šæ ·æ€§\"\"\"\n",
    "    config_dir = 'al_configs'\n",
    "    config_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(config_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                config_files.append(os.path.join(root, file))\n",
    "    \n",
    "    print(\"=== ä»…å›ºå®šéšæœºç§å­ ===\")\n",
    "    \n",
    "    for config_file in sorted(config_files):\n",
    "        try:\n",
    "            cfg = Config.fromfile(config_file)\n",
    "            filename = os.path.basename(config_file)\n",
    "            \n",
    "            # å›ºå®šå…¨å±€éšæœºç§å­\n",
    "            cfg.randomness = dict(\n",
    "                seed=42,\n",
    "                deterministic=True,\n",
    "                diff_rank_seed=False\n",
    "            )\n",
    "            \n",
    "            # å›ºå®šæ•°æ®é‡‡æ ·å™¨ç§å­ï¼Œä½†ä¿æŒshuffle\n",
    "            if hasattr(cfg, 'train_dataloader'):\n",
    "                cfg.train_dataloader.sampler = dict(\n",
    "                    type='DefaultSampler',\n",
    "                    shuffle=True,  # ä¿æŒshuffleä½†ç§å­å›ºå®š\n",
    "                    seed=42\n",
    "                )\n",
    "            \n",
    "            cfg.dump(config_file)\n",
    "            print(f\"âœ“ {filename}: å·²å›ºå®šç§å­\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— {filename}: {e}\")\n",
    "\n",
    "# ç»ˆæè§£å†³æ–¹æ¡ˆï¼šç¡®ä¿æ‰€æœ‰ç­–ç•¥ä½¿ç”¨å®Œå…¨ç›¸åŒçš„è®­ç»ƒæ ·æœ¬é¡ºåº\n",
    "def ensure_identical_training_order():\n",
    "    \"\"\"\n",
    "    ç¡®ä¿æ‰€æœ‰é‡‡æ ·ç­–ç•¥åœ¨æ¯ä¸ªepochä¸­ä½¿ç”¨å®Œå…¨ç›¸åŒçš„æ ·æœ¬é¡ºåº\n",
    "    è¿™æ˜¯æœ€å½»åº•çš„è§£å†³æ–¹æ¡ˆ\n",
    "    \"\"\"\n",
    "    config_dir = 'al_configs'\n",
    "    \n",
    "    print(\"=== ç¡®ä¿è®­ç»ƒæ ·æœ¬é¡ºåºå®Œå…¨ä¸€è‡´ ===\")\n",
    "    print(\"æ–¹æ³•1: ä½¿ç”¨å›ºå®šçš„sample list\")\n",
    "    print(\"æ–¹æ³•2: ç¦ç”¨æ‰€æœ‰éšæœºæ€§\")\n",
    "    print(\"æ–¹æ³•3: ä½¿ç”¨ç›¸åŒçš„random state\")\n",
    "    \n",
    "    # æ·»åŠ ç¯å¢ƒå˜é‡é…ç½®\n",
    "    env_config = \"\"\"\n",
    "# æ·»åŠ åˆ°é…ç½®æ–‡ä»¶æœ«å°¾\n",
    "env_cfg = dict(\n",
    "    cudnn_benchmark=False,     # ç¦ç”¨cudnn benchmarkç¡®ä¿ç¡®å®šæ€§\n",
    "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
    "    dist_cfg=dict(backend='nccl')\n",
    ")\n",
    "\n",
    "# ç¡®ä¿å®Œå…¨ç¡®å®šæ€§çš„è®­ç»ƒ\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# è®¾ç½®æ‰€æœ‰éšæœºç§å­\n",
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_all_seeds(42)\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"æ¨èåœ¨ä¸»è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ ä»¥ä¸Šä»£ç ç¡®ä¿å®Œå…¨ç¡®å®šæ€§\")\n",
    "\n",
    "# æ‰§è¡Œé€‰æ‹©ï¼ˆå–æ¶ˆæ³¨é‡Šéœ€è¦çš„æ–¹æ¡ˆï¼‰\n",
    "# fix_minibatch_consistency()     # æœ€ä¸¥æ ¼ï¼šç¦ç”¨æ‰€æœ‰éšæœºæ€§\n",
    "# fix_seeds_only()                # ä¸­ç­‰ï¼šå›ºå®šç§å­ä½†ä¿æŒå¢å¼º\n",
    "# ensure_identical_training_order() # æŸ¥çœ‹ç»ˆææ–¹æ¡ˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸»åŠ¨å­¦ä¹ ä¸“ç”¨è§£å†³æ–¹æ¡ˆï¼šç¡®ä¿æ‰€æœ‰ç­–ç•¥åœ¨æ¯è½®ä½¿ç”¨ç›¸åŒçš„å·²æ ‡æ³¨æ•°æ®\n",
    "def sync_active_learning_data():\n",
    "    \"\"\"\n",
    "    ä¸»åŠ¨å­¦ä¹ åœºæ™¯ä¸‹çš„ç‰¹æ®Šå¤„ç†ï¼š\n",
    "    ç¡®ä¿ä¸åŒé‡‡æ ·ç­–ç•¥åœ¨æ¯ä¸€è½®è®­ç»ƒä¸­ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å·²æ ‡æ³¨æ•°æ®æ± \n",
    "    \"\"\"\n",
    "    print(\"=== ä¸»åŠ¨å­¦ä¹ æ•°æ®åŒæ­¥æ–¹æ¡ˆ ===\")\n",
    "    print(\"\"\"\n",
    "    ä¸»åŠ¨å­¦ä¹ ä¸­mini-batchå·®å¼‚çš„æ ¸å¿ƒé—®é¢˜ï¼š\n",
    "    \n",
    "    1. é—®é¢˜æ ¹æºï¼š\n",
    "       - ä¸åŒé‡‡æ ·ç­–ç•¥é€‰æ‹©ä¸åŒçš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨\n",
    "       - å³ä½¿batch_sizeç›¸åŒï¼Œä½†æ¯è½®è®­ç»ƒçš„æ•°æ®æ± ä¸åŒ\n",
    "       - å¯¼è‡´æ¨¡å‹å­¦ä¹ åˆ°ä¸åŒçš„ç‰¹å¾åˆ†å¸ƒ\n",
    "    \n",
    "    2. è§£å†³æ–¹æ¡ˆï¼š\n",
    "       \n",
    "       æ–¹æ¡ˆA: å›ºå®šåˆå§‹æ ‡æ³¨æ± ï¼ˆæ¨èç”¨äºå¯¹æ¯”å®éªŒï¼‰\n",
    "       â”œâ”€â”€ æ‰€æœ‰ç­–ç•¥ä»ç›¸åŒçš„åˆå§‹æ ‡æ³¨æ ·æœ¬å¼€å§‹\n",
    "       â”œâ”€â”€ æ¯è½®è®­ç»ƒä½¿ç”¨å®Œå…¨ç›¸åŒçš„å·²æ ‡æ³¨æ•°æ®\n",
    "       â””â”€â”€ åªæœ‰æ–°é€‰æ‹©çš„æ ·æœ¬ä¸åŒï¼Œä½†å·²æ ‡æ³¨éƒ¨åˆ†ä¿æŒä¸€è‡´\n",
    "       \n",
    "       æ–¹æ¡ˆB: æ•°æ®å¢å¼ºä¸€è‡´æ€§\n",
    "       â”œâ”€â”€ å›ºå®šæ•°æ®å¢å¼ºçš„éšæœºç§å­\n",
    "       â”œâ”€â”€ ç¡®ä¿ç›¸åŒå›¾ç‰‡åœ¨ä¸åŒç­–ç•¥ä¸­å¾—åˆ°ç›¸åŒçš„å¢å¼º\n",
    "       â””â”€â”€ ä¿æŒè®­ç»ƒçš„éšæœºæ€§ä½†å¢å¼ºè¿‡ç¨‹ä¸€è‡´\n",
    "       \n",
    "       æ–¹æ¡ˆC: æ‰¹æ¬¡ç»„æˆæ§åˆ¶\n",
    "       â”œâ”€â”€ æ§åˆ¶æ¯ä¸ªbatchä¸­ä¸åŒç±»åˆ«æ ·æœ¬çš„æ¯”ä¾‹\n",
    "       â”œâ”€â”€ ç¡®ä¿ä¸åŒç­–ç•¥çš„batchæœ‰ç›¸ä¼¼çš„æ ·æœ¬åˆ†å¸ƒ\n",
    "       â””â”€â”€ ä½¿ç”¨ClassAwareSampleræˆ–è‡ªå®šä¹‰é‡‡æ ·å™¨\n",
    "    \n",
    "    3. å®ç°å»ºè®®ï¼š\n",
    "    \"\"\")\n",
    "    \n",
    "    # ä¸ºä¸»åŠ¨å­¦ä¹ æ·»åŠ ä¸“ç”¨é…ç½®\n",
    "    al_config_template = '''\n",
    "# ä¸»åŠ¨å­¦ä¹ ä¸“ç”¨é…ç½®\n",
    "active_learning = dict(\n",
    "    # æ•°æ®åŒæ­¥è®¾ç½®\n",
    "    sync_settings=dict(\n",
    "        use_fixed_initial_pool=True,        # ä½¿ç”¨å›ºå®šçš„åˆå§‹æ ‡æ³¨æ± \n",
    "        initial_pool_seed=42,               # åˆå§‹æ± é€‰æ‹©ç§å­\n",
    "        batch_composition_control=True,     # æ§åˆ¶batchç»„æˆ\n",
    "        augmentation_sync=True,             # åŒæ­¥æ•°æ®å¢å¼º\n",
    "    ),\n",
    "    \n",
    "    # ç¡®ä¿ä¸€è‡´çš„æ¨ç†è®¾ç½®\n",
    "    inference_options=dict(\n",
    "        batch_size=8,\n",
    "        deterministic=True,                 # ç¡®å®šæ€§æ¨ç†\n",
    "        score_thr=0.05,\n",
    "        seed=42,                           # æ¨ç†ç§å­\n",
    "    ),\n",
    "    \n",
    "    # æ ·æœ¬é€‰æ‹©åŒæ­¥\n",
    "    sample_selection=dict(\n",
    "        num_samples=200,\n",
    "        selection_seed=42,                  # é€‰æ‹©è¿‡ç¨‹ç§å­\n",
    "        use_deterministic_selection=True,   # ç¡®å®šæ€§é€‰æ‹©\n",
    "    )\n",
    ")\n",
    "\n",
    "# è®­ç»ƒé…ç½®åŒæ­¥\n",
    "train_cfg = dict(\n",
    "    type='EpochBasedTrainLoop',\n",
    "    max_epochs=3,\n",
    "    val_interval=1,\n",
    "    # ç¡®å®šæ€§è®­ç»ƒè®¾ç½®\n",
    "    deterministic=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# éšæœºæ€§æ§åˆ¶\n",
    "randomness = dict(\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    diff_rank_seed=False\n",
    ")\n",
    "'''\n",
    "    \n",
    "    print(\"å»ºè®®åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸ŠåŒæ­¥è®¾ç½®\")\n",
    "    print(\"\\n4. ä»£ç å®ç°ç¤ºä¾‹ï¼š\")\n",
    "    \n",
    "    code_example = '''\n",
    "# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ \n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def ensure_reproducibility():\n",
    "    # è®¾ç½®æ‰€æœ‰éšæœºç§å­\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # ç¡®å®šæ€§è®¾ç½®\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # ç¯å¢ƒå˜é‡\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# åœ¨æ¯è½®ä¸»åŠ¨å­¦ä¹ å¼€å§‹å‰è°ƒç”¨\n",
    "ensure_reproducibility()\n",
    "'''\n",
    "    \n",
    "    print(code_example)\n",
    "\n",
    "# å¿«é€Ÿä¿®å¤å‡½æ•°ï¼šæ·»åŠ ç¡®å®šæ€§è®¾ç½®åˆ°æ‰€æœ‰é…ç½®\n",
    "def add_deterministic_settings():\n",
    "    \"\"\"ä¸ºæ‰€æœ‰é…ç½®æ–‡ä»¶æ·»åŠ ç¡®å®šæ€§è®¾ç½®\"\"\"\n",
    "    config_dir = 'al_configs'\n",
    "    config_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(config_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                config_files.append(os.path.join(root, file))\n",
    "    \n",
    "    print(\"=== æ·»åŠ ç¡®å®šæ€§è®¾ç½® ===\")\n",
    "    \n",
    "    for config_file in sorted(config_files):\n",
    "        try:\n",
    "            cfg = Config.fromfile(config_file)\n",
    "            filename = os.path.basename(config_file)\n",
    "            \n",
    "            # æ·»åŠ éšæœºæ€§æ§åˆ¶\n",
    "            cfg.randomness = dict(seed=42, deterministic=True, diff_rank_seed=False)\n",
    "            \n",
    "            # ä¿®æ”¹ç¯å¢ƒé…ç½®\n",
    "            if not hasattr(cfg, 'env_cfg'):\n",
    "                cfg.env_cfg = dict()\n",
    "            cfg.env_cfg.update(dict(\n",
    "                cudnn_benchmark=False,  # é‡è¦ï¼šç¦ç”¨benchmarkç¡®ä¿ç¡®å®šæ€§\n",
    "                mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
    "                dist_cfg=dict(backend='nccl')\n",
    "            ))\n",
    "            \n",
    "            # ä¿®æ”¹æ•°æ®é‡‡æ ·å™¨ç¡®ä¿ä¸€è‡´æ€§\n",
    "            if hasattr(cfg, 'train_dataloader'):\n",
    "                cfg.train_dataloader.sampler = dict(\n",
    "                    type='DefaultSampler', \n",
    "                    shuffle=True,  # ä¿æŒshuffleä½†ç§å­å›ºå®š\n",
    "                    seed=42\n",
    "                )\n",
    "                \n",
    "                # æ·»åŠ workeråˆå§‹åŒ–å‡½æ•°ç¡®ä¿æ¯ä¸ªworkerçš„ç§å­ä¸€è‡´\n",
    "                cfg.train_dataloader.worker_init_fn = 'seed_worker'\n",
    "            \n",
    "            cfg.dump(config_file)\n",
    "            print(f\"âœ“ {filename}: å·²æ·»åŠ ç¡®å®šæ€§è®¾ç½®\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— {filename}: {e}\")\n",
    "    \n",
    "    print(\"=== ç¡®å®šæ€§è®¾ç½®æ·»åŠ å®Œæˆ ===\")\n",
    "\n",
    "# æ‰§è¡Œå‡½æ•°\n",
    "# add_deterministic_settings()  # å–æ¶ˆæ³¨é‡Šæ‰§è¡Œ\n",
    "# sync_active_learning_data()   # æŸ¥çœ‹è¯¦ç»†æ–¹æ¡ˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•å•ä¸ªé…ç½®æ–‡ä»¶\n",
    "config_path = 'al_configs/cascade-rcnn/cascade-rcnn_r101_ssc.py'\n",
    "\n",
    "# åŠ è½½é…ç½®æ–‡ä»¶\n",
    "cfg = Config.fromfile(config_path)\n",
    "\n",
    "# æŸ¥çœ‹å…³é”®é…ç½®ä¿¡æ¯\n",
    "print(\"=== å½“å‰é…ç½®ä¿¡æ¯ ===\")\n",
    "print(f\"æ•°æ®æ ¹ç›®å½•: {cfg.data_root}\")\n",
    "print(f\"è®­ç»ƒæ•°æ®: {cfg.train_dataloader.dataset.ann_file}\")\n",
    "print(f\"éªŒè¯æ•°æ®: {cfg.val_dataloader.dataset.ann_file}\")\n",
    "print(f\"ä¸»åŠ¨å­¦ä¹ æ•°æ®: {cfg.active_learning.ann_file}\")\n",
    "print(f\"å·¥ä½œç›®å½•: {getattr(cfg, 'work_dir', 'æœªè®¾ç½®')}\")\n",
    "print(f\"æ‰¹æ¬¡å¤§å°: {cfg.train_dataloader.batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38dcc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®æ–‡ä»¶åå¤„ç†å·¥å…·\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from mmengine import Config\n",
    "\n",
    "class ConfigPostProcessor:\n",
    "    def __init__(self, base_dir=\"al_configs\"):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        \n",
    "    def extract_info_from_filename(self, filepath):\n",
    "        \"\"\"ä»æ–‡ä»¶åä¸­æå–æ¨¡å‹ç±»å‹å’Œé‡‡æ ·æ–¹æ³•ä¿¡æ¯\"\"\"\n",
    "        filename = filepath.stem\n",
    "        \n",
    "        # æå–æ¨¡å‹ç±»å‹\n",
    "        if \"cascade-rcnn\" in filename:\n",
    "            model_type = \"cascade-rcnn\"\n",
    "        elif \"faster-rcnn\" in filename:\n",
    "            model_type = \"faster-rcnn\"\n",
    "        elif \"retinanet\" in filename:\n",
    "            model_type = \"retinanet\"\n",
    "        else:\n",
    "            model_type = \"unknown\"\n",
    "            \n",
    "        # æå–é‡‡æ ·æ–¹æ³•\n",
    "        sampling_methods = [\"ssc\", \"sor\", \"random\", \"entropy\", \"mus_cdb\", \"margin\", \"least_confidence\"]\n",
    "        sampling_method = \"unknown\"\n",
    "        \n",
    "        for method in sampling_methods:\n",
    "            if method in filename.replace(\"-\", \"_\").replace(\" \", \"_\"):\n",
    "                sampling_method = method\n",
    "                break\n",
    "                \n",
    "        return model_type, sampling_method\n",
    "    \n",
    "    def update_active_learning_paths(self, config_path):\n",
    "        \"\"\"æ›´æ–°ä¸»åŠ¨å­¦ä¹ ç›¸å…³çš„æ•°æ®è·¯å¾„\"\"\"\n",
    "        with open(config_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # ä»æ–‡ä»¶åæå–ä¿¡æ¯\n",
    "        model_type, sampling_method = self.extract_info_from_filename(config_path)\n",
    "        \n",
    "        # ç”Ÿæˆæ–°çš„è·¯å¾„\n",
    "        model_prefix = model_type.replace(\"-\", \"_\")\n",
    "        new_data_root = f\"data/ForestDamages/active_learning_{model_prefix}_{sampling_method}\"\n",
    "        \n",
    "        # æ›´æ–°è·¯å¾„çš„æ­£åˆ™è¡¨è¾¾å¼\n",
    "        patterns_replacements = [\n",
    "            # æ›´æ–° data_root\n",
    "            (r\"data_root\\s*=\\s*['\\\"][^'\\\"]*['\\\"]\", f\"data_root='{new_data_root}'\"),\n",
    "            # æ›´æ–° ann_file ä¸­çš„è·¯å¾„\n",
    "            (r\"ann_file\\s*=\\s*['\\\"]([^'\\\"]*)/annotations/instances_unlabeled\\.json['\\\"]\",\n",
    "             f\"ann_file='{new_data_root}/annotations/instances_unlabeled.json'\"),\n",
    "            # æ›´æ–° data_prefix ä¸­çš„è·¯å¾„\n",
    "            (r\"data_prefix\\s*=\\s*dict\\s*\\(\\s*img\\s*=\\s*['\\\"]([^'\\\"]*)/images_unlabeled['\\\"]\",\n",
    "             f\"data_prefix=dict(img='{new_data_root}/images_unlabeled'\"),\n",
    "            # æ›´æ–° train_pool_cfg ä¸­çš„è·¯å¾„\n",
    "            (r\"(train_pool_cfg\\s*=\\s*dict\\s*\\(\\s*data_root\\s*=\\s*['\\\"])[^'\\\"]*(['\\\"])\",\n",
    "             rf\"\\g<1>{new_data_root}\\g<2>\"),\n",
    "        ]\n",
    "        \n",
    "        for pattern, replacement in patterns_replacements:\n",
    "            content = re.sub(pattern, replacement, content)\n",
    "            \n",
    "        return content\n",
    "    \n",
    "    def update_batch_sizes(self, content, model_type, sampling_method):\n",
    "        \"\"\"æ ¹æ®æ¨¡å‹ç±»å‹å’Œé‡‡æ ·æ–¹æ³•ä¼˜åŒ–batch size\"\"\"\n",
    "        \n",
    "        # å®šä¹‰ä¸åŒæƒ…å†µä¸‹çš„æœ€ä¼˜batch size\n",
    "        batch_size_map = {\n",
    "            (\"cascade-rcnn\", \"sor\"): 2,      # SORæ–¹æ³•å†…å­˜éœ€æ±‚å¤§\n",
    "            (\"cascade-rcnn\", \"mus_cdb\"): 32, # MUS-CDBå¯ä»¥ç”¨è¾ƒå¤§batch\n",
    "            (\"faster-rcnn\", \"sor\"): 2,\n",
    "            (\"faster-rcnn\", \"mus_cdb\"): 32,\n",
    "            (\"retinanet\", \"sor\"): 4,         # RetinaNetç›¸å¯¹å†…å­˜å‹å¥½\n",
    "            (\"retinanet\", \"mus_cdb\"): 64,\n",
    "        }\n",
    "        \n",
    "        # é»˜è®¤batch size\n",
    "        default_batch_sizes = {\n",
    "            \"cascade-rcnn\": 16,\n",
    "            \"faster-rcnn\": 16, \n",
    "            \"retinanet\": 32\n",
    "        }\n",
    "        \n",
    "        # è·å–åˆé€‚çš„batch size\n",
    "        batch_size = batch_size_map.get(\n",
    "            (model_type, sampling_method), \n",
    "            default_batch_sizes.get(model_type, 16)\n",
    "        )\n",
    "        \n",
    "        # æ›´æ–°batch_size\n",
    "        content = re.sub(\n",
    "            r\"batch_size\\s*=\\s*\\d+\",\n",
    "            f\"batch_size={batch_size}\",\n",
    "            content\n",
    "        )\n",
    "        \n",
    "        return content\n",
    "    \n",
    "    def update_score_thresholds(self, content, model_type):\n",
    "        \"\"\"æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´æ£€æµ‹é˜ˆå€¼\"\"\"\n",
    "        \n",
    "        thresholds = {\n",
    "            \"cascade-rcnn\": {\"score\": 0.05, \"nms\": 0.5},  # Cascade R-CNNå¯ä»¥ç”¨æ›´ä½é˜ˆå€¼\n",
    "            \"faster-rcnn\": {\"score\": 0.08, \"nms\": 0.4},   # æ ‡å‡†è®¾ç½®\n",
    "            \"retinanet\": {\"score\": 0.1, \"nms\": 0.3}       # RetinaNetéœ€è¦æ›´é«˜é˜ˆå€¼\n",
    "        }\n",
    "        \n",
    "        if model_type in thresholds:\n",
    "            threshold_info = thresholds[model_type]\n",
    "            \n",
    "            # æ›´æ–° score_threshold\n",
    "            content = re.sub(\n",
    "                r\"score_threshold\\s*=\\s*[\\d.]+\",\n",
    "                f\"score_threshold = {threshold_info['score']}\",\n",
    "                content\n",
    "            )\n",
    "            \n",
    "            # æ›´æ–° nms_iou_threshold  \n",
    "            content = re.sub(\n",
    "                r\"nms_iou_threshold\\s*=\\s*[\\d.]+\",\n",
    "                f\"nms_iou_threshold = {threshold_info['nms']}\",\n",
    "                content\n",
    "            )\n",
    "            \n",
    "        return content\n",
    "    \n",
    "    def add_missing_work_dir(self, content, config_path):\n",
    "        \"\"\"æ·»åŠ å·¥ä½œç›®å½•é…ç½®\"\"\"\n",
    "        filename = config_path.stem\n",
    "        \n",
    "        if \"work_dir\" not in content:\n",
    "            work_dir = f\"work_dirs/{filename}\"\n",
    "            content += f\"\\n\\n# å·¥ä½œç›®å½•\\nwork_dir = '{work_dir}'\\n\"\n",
    "            \n",
    "        return content\n",
    "    \n",
    "    def process_config_file(self, config_path):\n",
    "        \"\"\"å¤„ç†å•ä¸ªé…ç½®æ–‡ä»¶\"\"\"\n",
    "        print(f\"ğŸ”§ å¤„ç†é…ç½®æ–‡ä»¶: {config_path}\")\n",
    "        \n",
    "        # æå–æ¨¡å‹ä¿¡æ¯\n",
    "        model_type, sampling_method = self.extract_info_from_filename(config_path)\n",
    "        print(f\"   æ¨¡å‹: {model_type}, é‡‡æ ·æ–¹æ³•: {sampling_method}\")\n",
    "        \n",
    "        # æ›´æ–°è·¯å¾„\n",
    "        content = self.update_active_learning_paths(config_path)\n",
    "        \n",
    "        # æ›´æ–°å‚æ•°\n",
    "        content = self.update_batch_sizes(content, model_type, sampling_method)\n",
    "        content = self.update_score_thresholds(content, model_type)\n",
    "        content = self.add_missing_work_dir(content, config_path)\n",
    "        \n",
    "        # ä¿å­˜æ–‡ä»¶\n",
    "        with open(config_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "            \n",
    "        print(f\"   âœ… å®Œæˆ\")\n",
    "        return True\n",
    "    \n",
    "    def get_all_config_files(self):\n",
    "        \"\"\"è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶è·¯å¾„\"\"\"\n",
    "        config_files = []\n",
    "        model_types = [\"cascade-rcnn\", \"faster-rcnn\", \"retinanet\"]\n",
    "        \n",
    "        for model_type in model_types:\n",
    "            model_dir = self.base_dir / model_type\n",
    "            if model_dir.exists():\n",
    "                config_files.extend(list(model_dir.glob(\"*.py\")))\n",
    "        return config_files\n",
    "    \n",
    "    def process_all_configs(self):\n",
    "        \"\"\"å¤„ç†æ‰€æœ‰é…ç½®æ–‡ä»¶\"\"\"\n",
    "        config_files = self.get_all_config_files()\n",
    "        \n",
    "        print(f\"ğŸš€ æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        success_count = 0\n",
    "        for config_file in config_files:\n",
    "            try:\n",
    "                if self.process_config_file(config_file):\n",
    "                    success_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ å¤„ç† {config_file} æ—¶å‡ºé”™: {e}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(f\"âœ… å¤„ç†å®Œæˆ: {success_count}/{len(config_files)} ä¸ªæ–‡ä»¶æˆåŠŸ\")\n",
    "        \n",
    "        return success_count == len(config_files)\n",
    "    \n",
    "    def validate_config(self, config_path):\n",
    "        \"\"\"éªŒè¯é…ç½®æ–‡ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸åŠ è½½\"\"\"\n",
    "        try:\n",
    "            cfg = Config.fromfile(str(config_path))\n",
    "            print(f\"âœ… é…ç½®æ–‡ä»¶éªŒè¯æˆåŠŸ: {config_path.name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {config_path.name}, é”™è¯¯: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def validate_all_configs(self):\n",
    "        \"\"\"éªŒè¯æ‰€æœ‰é…ç½®æ–‡ä»¶\"\"\"\n",
    "        config_files = self.get_all_config_files()\n",
    "        \n",
    "        print(\"ğŸ” éªŒè¯æ‰€æœ‰é…ç½®æ–‡ä»¶...\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        success_count = 0\n",
    "        for config_file in config_files:\n",
    "            if self.validate_config(config_file):\n",
    "                success_count += 1\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(f\"éªŒè¯å®Œæˆ: {success_count}/{len(config_files)} ä¸ªé…ç½®æ–‡ä»¶é€šè¿‡éªŒè¯\")\n",
    "\n",
    "# åˆ›å»ºå¤„ç†å™¨å®ä¾‹\n",
    "processor = ConfigPostProcessor()\n",
    "print(\"âœ… é…ç½®æ–‡ä»¶åå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ æ‰§è¡Œé…ç½®æ–‡ä»¶åå¤„ç†\n",
    "print(\"å¼€å§‹å¤„ç†æ‰€æœ‰é…ç½®æ–‡ä»¶...\")\n",
    "success = processor.process_all_configs()\n",
    "\n",
    "if success:\n",
    "    print(\"\\nğŸ‰ æ‰€æœ‰é…ç½®æ–‡ä»¶æ›´æ–°æˆåŠŸ!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ éƒ¨åˆ†é…ç½®æ–‡ä»¶æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” éªŒè¯é…ç½®æ–‡ä»¶åŠ è½½\n",
    "print(\"éªŒè¯é…ç½®æ–‡ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸åŠ è½½...\")\n",
    "processor.validate_all_configs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª æµ‹è¯•å•ä¸ªé…ç½®æ–‡ä»¶åŠ è½½ (åŸæœ‰çš„æµ‹è¯•ä»£ç )\n",
    "print(\"æµ‹è¯•å•ä¸ªé…ç½®æ–‡ä»¶åŠ è½½...\")\n",
    "\n",
    "try:\n",
    "    # åŠ è½½é…ç½®æ–‡ä»¶\n",
    "    cfg = Config.fromfile('al_configs/cascade-rcnn/cascade-rcnn_F_r101_ssc_16_200.py')\n",
    "    \n",
    "    # æ‰“å°é…ç½®ä¿¡æ¯\n",
    "    print(\"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ!\")\n",
    "    print(f\"æ¨¡å‹ç±»å‹: {cfg.model.type}\")\n",
    "    print(f\"æ•°æ®æ ¹ç›®å½•: {cfg.active_learning.data_root}\")\n",
    "    print(f\"æ£€æµ‹é˜ˆå€¼: {cfg.score_threshold}\")\n",
    "    print(f\"æœ€å¤§æ£€æµ‹æ¡†æ•°: {cfg.max_boxes_per_img}\")\n",
    "    \n",
    "    # ä¿å­˜åˆ°æ–‡ä»¶\n",
    "    with open('generated_config.py', 'w') as f:\n",
    "        f.write(cfg.pretty_text)\n",
    "    print(\"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ° generated_config.py\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ¯ é…ç½®æ–‡ä»¶åå¤„ç†è¯´æ˜\n",
    "\n",
    "### ä¸»è¦åŠŸèƒ½ï¼š\n",
    "1. **è‡ªåŠ¨è·¯å¾„æ›´æ–°**ï¼šæ ¹æ®æ–‡ä»¶åè‡ªåŠ¨ç”Ÿæˆæ­£ç¡®çš„ä¸»åŠ¨å­¦ä¹ æ•°æ®è·¯å¾„\n",
    "2. **æ™ºèƒ½å‚æ•°è°ƒæ•´**ï¼š\n",
    "   - SORæ–¹æ³•ä½¿ç”¨è¾ƒå°batch size (å†…å­˜éœ€æ±‚å¤§)\n",
    "   - MUS-CDBæ–¹æ³•ä½¿ç”¨è¾ƒå¤§batch size (å¯å¹¶è¡Œå¤„ç†)\n",
    "   - æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´æ£€æµ‹é˜ˆå€¼\n",
    "3. **å·¥ä½œç›®å½•é…ç½®**ï¼šè‡ªåŠ¨æ·»åŠ å·¥ä½œç›®å½•é…ç½®\n",
    "4. **éªŒè¯æœºåˆ¶**ï¼šç¡®ä¿å¤„ç†åçš„é…ç½®æ–‡ä»¶å¯ä»¥æ­£å¸¸åŠ è½½\n",
    "\n",
    "### å‚æ•°ä¼˜åŒ–ç­–ç•¥ï¼š\n",
    "- **Cascade R-CNN**: `batch_size=16`, `score_threshold=0.05`\n",
    "- **Faster R-CNN**: `batch_size=16`, `score_threshold=0.08`\n",
    "- **RetinaNet**: `batch_size=32`, `score_threshold=0.1`\n",
    "\n",
    "### ç‰¹æ®Šæ–¹æ³•ä¼˜åŒ–ï¼š\n",
    "- **SORæ–¹æ³•**: `batch_size=2` (å†…å­˜å‹å¥½)\n",
    "- **MUS-CDBæ–¹æ³•**: `batch_size=32+` (é«˜æ•ˆå¹¶è¡Œ)\n",
    "\n",
    "### ä½¿ç”¨æ–¹æ³•ï¼š\n",
    "1. è¿è¡Œç¬¬ä¸€ä¸ªcellåˆå§‹åŒ–å¤„ç†å™¨\n",
    "2. è¿è¡Œç¬¬äºŒä¸ªcellæ‰§è¡Œæ‰¹é‡å¤„ç†\n",
    "3. è¿è¡Œç¬¬ä¸‰ä¸ªcelléªŒè¯æ‰€æœ‰é…ç½®æ–‡ä»¶\n",
    "4. è¿è¡Œç¬¬å››ä¸ªcellæµ‹è¯•å•ä¸ªé…ç½®æ–‡ä»¶åŠ è½½\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812127f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_cascade_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_cascade_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_cascade_ssc',\n",
      "    inference_options=dict(\n",
      "        batch_size=16,\n",
      "        sample_size=0,\n",
      "        save_results=True,\n",
      "        score_thr=0.08,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(\n",
      "        num_samples=200,\n",
      "        rl_metric='',\n",
      "        sample_selector='default',\n",
      "        uncertainty_metric='ssc_score'),\n",
      "    train_pool_cfg=dict(\n",
      "        ann_file='annotations/instances_labeled_train.json',\n",
      "        data_prefix=dict(img='images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_cascade_ssc'))\n",
      "data_root = 'data/ForestDamages/active_learning_cascade_sor'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_boxes_per_img = 250\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=1.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                num_classes=5,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=1.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                num_classes=5,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    alpha=0.25,\n",
      "                    gamma=2.0,\n",
      "                    loss_weight=1.0,\n",
      "                    type='FocalLoss',\n",
      "                    use_sigmoid=True),\n",
      "                num_classes=5,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='CascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            alpha=0.25,\n",
      "            gamma=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='FocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=250,\n",
      "            nms=dict(iou_threshold=0.4, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='CascadeRCNN')\n",
      "nms_iou_threshold = 0.4\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=35, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.0001, type='AdamW', weight_decay=0.05),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=48,\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=48,\n",
      "        eta_min=1e-06,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "score_threshold = 0.08\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1280,\n",
      "                1280,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1536,\n",
      "        1536,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=3, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_cascade_sor/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            'data/ForestDamages/active_learning_cascade_sor/images_labeled_train'\n",
      "        ),\n",
      "        data_root='data/ForestDamages/active_learning_cascade_sor',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1280,\n",
      "                1280,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1280,\n",
      "        1280,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -20,\n",
      "        20,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_cascade_sor/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img=\n",
      "            'data/ForestDamages/active_learning_cascade_sor/images_labeled_val'\n",
      "        ),\n",
      "        data_root='data/ForestDamages/active_learning_cascade_sor',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1536,\n",
      "                1536,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_cascade_sor/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "    dict(type='TensorboardVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "    ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmengine import Config\n",
    "\n",
    "# åŠ è½½é…ç½®æ–‡ä»¶\n",
    "cfg = Config.fromfile('al_configs/cascade-rcnn/cascade-rcnn_F_r101_ssc_16_200.py')\n",
    "\n",
    "    # ç›´æ¥ä¿®æ”¹cfgçš„å±æ€§\n",
    "    # 1. ä¿®æ”¹æ•°æ®æ ¹ç›®å½•\n",
    "cfg.data_root = data_root\n",
    "\n",
    "# 2. ä¿®æ”¹è®­ç»ƒæ•°æ®åŠ è½½å™¨è·¯å¾„\n",
    "cfg.train_dataloader.dataset.data_root = data_root\n",
    "cfg.train_dataloader.dataset.ann_file = f'{data_root}/annotations/instances_labeled_train.json'\n",
    "cfg.train_dataloader.dataset.data_prefix.img = f'{data_root}/images_labeled_train'\n",
    "\n",
    "# 3. ä¿®æ”¹éªŒè¯æ•°æ®åŠ è½½å™¨è·¯å¾„  \n",
    "cfg.val_dataloader.dataset.data_root = data_root\n",
    "cfg.val_dataloader.dataset.ann_file = f'{data_root}/annotations/instances_labeled_val.json'\n",
    "cfg.val_dataloader.dataset.data_prefix.img = f'{data_root}/images_labeled_val'\n",
    "\n",
    "# 4. ä¿®æ”¹éªŒè¯è¯„ä¼°å™¨è·¯å¾„\n",
    "cfg.val_evaluator.ann_file = f'{data_root}/annotations/instances_labeled_val.json'\n",
    "\n",
    "# 5. ä¿®æ”¹active_learningé…ç½®è·¯å¾„\n",
    "cfg.active_learning.data_root = data_root\n",
    "cfg.active_learning.ann_file = f'{data_root}/annotations/instances_unlabeled.json'\n",
    "cfg.active_learning.data_prefix.img = f'{data_root}/images_unlabeled'\n",
    "cfg.active_learning.train_pool_cfg.data_root = data_root\n",
    "\n",
    "# 6. è®¾ç½®å·¥ä½œç›®å½•\n",
    "cfg.work_dir = f'work_dirs/{model_type}_{sampling_method}'\n",
    "\n",
    "# æ‰“å°é…ç½®ä¿¡æ¯\n",
    "print(cfg.pretty_text)\n",
    "\n",
    "# ä¿å­˜åˆ°æ–‡ä»¶\n",
    "with open('try.py', 'w') as f:\n",
    "    f.write(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55fab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "->\n",
    "\n",
    "from mmengine import Config\n",
    "import os\n",
    "\n",
    "# ç®€åŒ–çš„é…ç½®æ–‡ä»¶ä¿®æ”¹æ–¹æ³•\n",
    "def update_single_config(config_path):\n",
    "    \"\"\"ç›´æ¥é€šè¿‡cfgå±æ€§ä¿®æ”¹é…ç½®æ–‡ä»¶\"\"\"\n",
    "    # åŠ è½½é…ç½®æ–‡ä»¶\n",
    "    cfg = Config.fromfile(config_path)\n",
    "    \n",
    "    # ä»æ–‡ä»¶åæå–ä¿¡æ¯\n",
    "    filename = os.path.basename(config_path)\n",
    "    \n",
    "    # ç¡®å®šæ¨¡å‹ç±»å‹\n",
    "    if 'cascade-rcnn' in filename:\n",
    "        model_type = 'cascade'\n",
    "    elif 'faster-rcnn' in filename:\n",
    "        model_type = 'faster'\n",
    "    elif 'retinanet' in filename:\n",
    "        model_type = 'retinanet'\n",
    "    else:\n",
    "        model_type = 'cascade'\n",
    "    \n",
    "    # ç¡®å®šé‡‡æ ·æ–¹æ³•\n",
    "    sampling_methods = ['ssc', 'sor', 'random', 'entropy', 'mus_cdb', 'margin', 'least_confidence']\n",
    "    sampling_method = 'ssc'  # é»˜è®¤å€¼\n",
    "    for method in sampling_methods:\n",
    "        if method in filename:\n",
    "            sampling_method = method\n",
    "            break\n",
    "    \n",
    "    print(f\"æ›´æ–°é…ç½®: {filename} ({model_type}_{sampling_method})\")\n",
    "    \n",
    "    # æ„å»ºæ–°çš„æ•°æ®è·¯å¾„\n",
    "    data_root = f'data/ForestDamages/active_learning_{model_type}_{sampling_method}'\n",
    "    \n",
    "    # ç›´æ¥ä¿®æ”¹cfgçš„å±æ€§\n",
    "    # 1. ä¿®æ”¹æ•°æ®æ ¹ç›®å½•\n",
    "    cfg.data_root = data_root\n",
    "    \n",
    "    # 2. ä¿®æ”¹è®­ç»ƒæ•°æ®åŠ è½½å™¨è·¯å¾„\n",
    "    cfg.train_dataloader.dataset.data_root = data_root\n",
    "    cfg.train_dataloader.dataset.ann_file = f'{data_root}/annotations/instances_labeled_train.json'\n",
    "    cfg.train_dataloader.dataset.data_prefix.img = f'{data_root}/images_labeled_train'\n",
    "    \n",
    "    # 3. ä¿®æ”¹éªŒè¯æ•°æ®åŠ è½½å™¨è·¯å¾„  \n",
    "    cfg.val_dataloader.dataset.data_root = data_root\n",
    "    cfg.val_dataloader.dataset.ann_file = f'{data_root}/annotations/instances_labeled_val.json'\n",
    "    cfg.val_dataloader.dataset.data_prefix.img = f'{data_root}/images_labeled_val'\n",
    "    \n",
    "    # 4. ä¿®æ”¹éªŒè¯è¯„ä¼°å™¨è·¯å¾„\n",
    "    cfg.val_evaluator.ann_file = f'{data_root}/annotations/instances_labeled_val.json'\n",
    "    \n",
    "    # 5. ä¿®æ”¹active_learningé…ç½®è·¯å¾„\n",
    "    cfg.active_learning.data_root = data_root\n",
    "    cfg.active_learning.ann_file = f'{data_root}/annotations/instances_unlabeled.json'\n",
    "    cfg.active_learning.data_prefix.img = f'{data_root}/images_unlabeled'\n",
    "    cfg.active_learning.train_pool_cfg.data_root = data_root\n",
    "    \n",
    "    # 6. è®¾ç½®å·¥ä½œç›®å½•\n",
    "    cfg.work_dir = f'work_dirs/{model_type}_{sampling_method}'\n",
    "    \n",
    "    # ä¿å­˜ä¿®æ”¹åçš„é…ç½®\n",
    "    cfg.dump(config_path)\n",
    "    print(f\"âœ“ å·²ä¿å­˜: {data_root}\")\n",
    "\n",
    "# æ‰¹é‡æ›´æ–°æ‰€æœ‰é…ç½®æ–‡ä»¶\n",
    "config_dir = 'al_configs'\n",
    "config_files = []\n",
    "\n",
    "# æ”¶é›†æ‰€æœ‰é…ç½®æ–‡ä»¶\n",
    "for root, dirs, files in os.walk(config_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.py'):\n",
    "            config_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶\")\n",
    "\n",
    "# æ‰¹é‡æ›´æ–°\n",
    "for config_file in sorted(config_files):\n",
    "    try:\n",
    "        update_single_config(config_file)\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— æ›´æ–°å¤±è´¥ {config_file}: {e}\")\n",
    "\n",
    "print(\"æ‰¹é‡æ›´æ–°å®Œæˆï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
