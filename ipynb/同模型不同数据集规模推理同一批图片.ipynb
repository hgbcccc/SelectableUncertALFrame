{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_100/faster-rcnn_coco_100.py work_dirs/faster-rcnn_coco_100/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_100 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n",
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_200/faster-rcnn_coco_200.py work_dirs/faster-rcnn_coco_200/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_200 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n",
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_300/faster-rcnn_coco_300.py work_dirs/faster-rcnn_coco_300/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_300 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n",
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_500/faster-rcnn_coco_500.py work_dirs/faster-rcnn_coco_500/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_500 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n",
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_700/faster-rcnn_coco_700.py work_dirs/faster-rcnn_coco_700/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_700 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n",
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_900/faster-rcnn_coco_900.py work_dirs/faster-rcnn_coco_900/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_900 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n",
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_1100/faster-rcnn_coco_1100.py work_dirs/faster-rcnn_coco_1100/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_1100 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n",
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_1500/faster-rcnn_coco_1500.py work_dirs/faster-rcnn_coco_1500/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_1500 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n",
      "Running: python -m sual.inference.detector work_dirs/faster-rcnn_coco_1700/faster-rcnn_coco_1700.py work_dirs/faster-rcnn_coco_1700/epoch_20.pth ./data/Eucalyptus_canopy/test2017 --device cuda:0 --batch-size 8 --num-workers 4 --use-fp16 --output-dir test/cannoy_1700 --score-thr 0.01 --nms-thr 0.01 --max-det 300 --uncertainty-methods sor --vis-scale 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def batch_inference_detector(script_path, config_template, checkpoint_template, image_folder, output_folder, dataset_sizes, device=\"cuda:0\", batch_size=8, num_workers=4, use_fp16=True, score_thr=0.4, nms_thr=0.3, max_det=100, uncertainty_methods=\"sor\", vis_scale=1.0):\n",
    "    \"\"\"\n",
    "    批量运行 sual.inference.detector 模块。\n",
    "\n",
    "    :param script_path: 模块的路径\n",
    "    :param config_template: 配置文件路径模板，包含 {num} 占位符\n",
    "    :param checkpoint_template: 检查点文件路径模板，包含 {num} 占位符\n",
    "    :param image_folder: 图像文件夹路径\n",
    "    :param output_folder: 输出文件夹路径模板，包含 {num} 占位符\n",
    "    :param dataset_sizes: 数据集规模列表\n",
    "    :param device: 设备类型 (如 \"cuda:0\")\n",
    "    :param batch_size: 批量大小\n",
    "    :param num_workers: 数据加载的线程数\n",
    "    :param use_fp16: 是否使用 FP16\n",
    "    :param score_thr: 置信度分数阈值\n",
    "    :param nms_thr: NMS 阈值\n",
    "    :param max_det: 最大检测数量\n",
    "    :param uncertainty_methods: 不确定性度量方法\n",
    "    :param vis_scale: 可视化比例\n",
    "    \"\"\"\n",
    "    for num in dataset_sizes:\n",
    "        config_path = config_template.format(num=num)\n",
    "        checkpoint_path = checkpoint_template.format(num=num)\n",
    "        output_path = os.path.join(output_folder.format(num=num))\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        # 检查配置文件和检查点是否存在\n",
    "        if not os.path.exists(config_path):\n",
    "            print(f\"Config file not found: {config_path}. Skipping this dataset size.\")\n",
    "            continue\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            print(f\"Checkpoint file not found: {checkpoint_path}. Skipping this dataset size.\")\n",
    "            continue\n",
    "\n",
    "        command = [\n",
    "            \"python\", \"-m\", script_path,\n",
    "            config_path,\n",
    "            checkpoint_path,\n",
    "            image_folder,\n",
    "            \"--device\", device,\n",
    "            \"--batch-size\", str(batch_size),\n",
    "            \"--num-workers\", str(num_workers),\n",
    "            \"--use-fp16\" if use_fp16 else \"\",\n",
    "            \"--output-dir\", output_path,\n",
    "            \"--score-thr\", str(score_thr),\n",
    "            \"--nms-thr\", str(nms_thr),\n",
    "            \"--max-det\", str(max_det),\n",
    "            \"--uncertainty-methods\", uncertainty_methods,\n",
    "            \"--vis-scale\", str(vis_scale)\n",
    "        ]\n",
    "\n",
    "        # 移除空字符串参数\n",
    "        command = [arg for arg in command if arg]\n",
    "\n",
    "        print(f\"Running: {' '.join(command)}\")\n",
    "        try:\n",
    "            subprocess.run(command, check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error running command for dataset size {num}: {e}\")\n",
    "            continue  # 跳过当前任务，继续下一个任务\n",
    "\n",
    "# 示例用法\n",
    "script_path = \"sual.inference.detector\"\n",
    "config_template = \"work_dirs/faster-rcnn_coco_{num}/faster-rcnn_coco_{num}.py\"\n",
    "checkpoint_template = \"work_dirs/faster-rcnn_coco_{num}/epoch_20.pth\"\n",
    "image_folder = \"./data/Eucalyptus_canopy/test2017\"\n",
    "output_folder = \"test/cannoy_{num}\"\n",
    "\n",
    "dataset_sizes = [100, 200, 300, 500, 700, 900, 1100, 1500, 1700]\n",
    "\n",
    "batch_inference_detector(\n",
    "    script_path=script_path,\n",
    "    config_template=config_template,\n",
    "    checkpoint_template=checkpoint_template,\n",
    "    image_folder=image_folder,\n",
    "    output_folder=output_folder,\n",
    "    dataset_sizes=dataset_sizes,\n",
    "    device=\"cuda:0\",\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    "    use_fp16=True,\n",
    "    score_thr=0.01,\n",
    "    nms_thr=0.01,\n",
    "    max_det=300,\n",
    "    uncertainty_methods=\"sor\",\n",
    "    vis_scale=1.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
