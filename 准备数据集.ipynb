{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/prepare_active_dataset.py \\\n",
    "    data/ForestDamages \\\n",
    "    data/ForestDamages/active_learning_box \\\n",
    "    --train-ratio 0.04 \\\n",
    "    --val-ratio 0.01 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并数据集...\n",
      "数据根目录: /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages\n",
      "训练集标注文件: /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/annotations/instances_train2024.json\n",
      "验证集标注文件: /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/annotations/instances_val2024.json\n",
      "训练集图片目录: /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/train2024\n",
      "验证集图片目录: /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/val2024\n",
      "合并后总图像数: 1692\n",
      "合并后总标注数: 94615\n",
      "\n",
      "数据集分割:\n",
      "总样本数: 1692\n",
      "训练集大小: 67 (4.0%)\n",
      "验证集大小: 16 (1.0%)\n",
      "未标注集大小: 1609 (95.0%)\n",
      "\n",
      "处理 labeled_train 数据集...\n",
      "从以下目录复制图片:\n",
      "  - /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/train2024\n",
      "  - /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/val2024\n",
      "成功复制 67 张图片到 data/ForestDamages/active_learning_ssc/images_labeled_train\n",
      "保存标注到: data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json\n",
      "图像数量: 67\n",
      "标注数量: 3774\n",
      "\n",
      "处理 labeled_val 数据集...\n",
      "从以下目录复制图片:\n",
      "  - /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/train2024\n",
      "  - /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/val2024\n",
      "成功复制 16 张图片到 data/ForestDamages/active_learning_ssc/images_labeled_val\n",
      "保存标注到: data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json\n",
      "图像数量: 16\n",
      "标注数量: 1061\n",
      "\n",
      "处理 unlabeled 数据集...\n",
      "从以下目录复制图片:\n",
      "  - /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/train2024\n",
      "  - /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/data/ForestDamages/val2024\n",
      "成功复制 1609 张图片到 data/ForestDamages/active_learning_ssc/images_unlabeled\n",
      "保存标注到: data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json\n",
      "图像数量: 1609\n",
      "标注数量: 89780\n",
      "\n",
      "数据集准备完成!\n",
      "\n",
      "目录结构:\n",
      "data/ForestDamages/active_learning_ssc/\n",
      "├── images_labeled_train/\n",
      "├── images_labeled_val/\n",
      "├── images_unlabeled/\n",
      "└── annotations/\n",
      "    ├── instances_labeled_train.json\n",
      "    ├── instances_labeled_val.json\n",
      "    └── instances_unlabeled.json\n"
     ]
    }
   ],
   "source": [
    "!python sual/tools/prepare_dataset/prepare_active_dataset.py \\\n",
    "    data/ForestDamages \\\n",
    "    data/ForestDamages/active_learning_ssc \\\n",
    "    --train-ratio 0.04 \\\n",
    "    --val-ratio 0.01 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/prepare_active_dataset.py \\\n",
    "    data/ForestDamages \\\n",
    "    data/ForestDamages/active_learning_sor \\\n",
    "    --train-ratio 0.04 \\\n",
    "    --val-ratio 0.01 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据根目录: data/ForestDamages/active_learning_ssc\n",
      "训练集图片目录: data/ForestDamages/active_learning_ssc/images_labeled_train\n",
      "训练集标注文件: data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json\n",
      "\n",
      "开始第 1/16 轮主动学习...\n",
      "03/18 22:08:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 129488616\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 129488616\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:08:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_1'\n",
      "\n",
      "03/18 22:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:08:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:08:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "03/18 22:08:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:08:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/18 22:08:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_1.\n",
      "03/18 22:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/11]  lr: 2.0891e-04  eta: 0:00:01  time: 1.6632  data_time: 0.1097  memory: 6607  loss: 3.0378  loss_rpn_cls: 0.6897  loss_rpn_bbox: 0.3295  loss_cls: 1.3129  acc: 78.0273  loss_bbox: 0.7057\n",
      "03/18 22:09:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_220852\n",
      "03/18 22:09:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:09:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.017\n",
      "03/18 22:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-----+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-----+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0 | 0.001  | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0 | 0.001  | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0 | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.0 | 0.002  | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Spruce   | 0.0 | 0.001  | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "+----------+-----+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.001 0.000 0.000 -1.000 0.000 0.000\n",
      "03/18 22:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0000  coco/Spruce_precision: 0.0000  coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0010  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0000  data_time: 0.6560  time: 3.1815\n",
      "03/18 22:09:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.017\n",
      "03/18 22:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-----+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-----+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0 | 0.001  | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0 | 0.001  | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0 | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.0 | 0.002  | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Spruce   | 0.0 | 0.001  | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "+----------+-----+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.001 0.000 0.000 -1.000 0.000 0.000\n",
      "03/18 22:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0000  coco/Spruce_precision: 0.0000  coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0010  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0000  data_time: 0.5293  time: 2.9689\n",
      "03/18 22:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.0, bbox_mAP_50: 0.001, bbox_mAP_75: 0.0\n",
      "03/18 22:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_1/epoch_1.pth\n",
      "03/18 22:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_1/epoch_1.pth\n",
      "2025-03-18 22:09:29,936 - sual.inference.simdetector - INFO - 找到 87 张图片\n",
      "处理图片: 100%|█████████████████████████████████| 87/87 [00:09<00:00,  9.23it/s]\n",
      "2025-03-18 22:09:39,369 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 87/87 [00:43<00:00,  1.98it/s]\n",
      "2025-03-18 22:10:23,288 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_1/train_inference/20250318_220929/uncertainty/uncertainty_results.json\n",
      "03/18 22:10:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_1/train_stats.json\n",
      "03/18 22:10:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_1/epoch_1.pth\n",
      "03/18 22:10:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:10:24,498 - sual.inference.simdetector - INFO - 找到 1589 张图片\n",
      "2025-03-18 22:10:24,498 - sual.inference.simdetector - INFO - 找到 1589 张图片\n",
      "2025-03-18 22:10:24,498 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1589 张)\n",
      "2025-03-18 22:10:24,498 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1589 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:08<00:00,  2.26it/s]\n",
      "2025-03-18 22:10:33,353 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:10:33,353 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:10<00:00,  1.99it/s]\n",
      "2025-03-18 22:10:43,394 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_1/teacher_outputs/20250318_221024/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:10:43,394 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_1/teacher_outputs/20250318_221024/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 63.9276\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:10:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:10:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -2812.8493\n",
      "03/18 22:10:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:10:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 1 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 97\n",
      "  - 未标注图片数: 1579\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 5.79%\n",
      "  - 已标注框数量: 5630\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0000\n",
      "  - bbox_mAP_50: 0.0010\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 2/16 轮主动学习...\n",
      "03/18 22:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_1/epoch_1.pth\n",
      "03/18 22:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_1/epoch_1.pth\n",
      "03/18 22:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 648906398\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 648906398\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:10:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_1/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_2'\n",
      "\n",
      "03/18 22:10:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:10:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_1/epoch_1.pth\n",
      "03/18 22:12:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_1/epoch_1.pth\n",
      "03/18 22:12:25 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:12:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_2.\n",
      "03/18 22:12:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/13]  lr: 2.0891e-04  eta: 0:00:04  time: 1.6212  data_time: 0.1031  memory: 6848  loss: 2.8783  loss_rpn_cls: 0.6813  loss_rpn_bbox: 0.3210  loss_cls: 1.0273  acc: 76.9287  loss_bbox: 0.8487\n",
      "03/18 22:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_221045\n",
      "03/18 22:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.55s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.011\n",
      "03/18 22:12:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Spruce   | 0.001 | 0.004  | 0.0    | 0.0    | nan   | 0.002 | 0.001 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:12:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.001 0.000 0.000 -1.000 0.000 0.000\n",
      "03/18 22:12:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0000  coco/Spruce_precision: 0.0010  coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0010  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0000  data_time: 0.7221  time: 3.1550\n",
      "03/18 22:12:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.51s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.011\n",
      "03/18 22:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Spruce   | 0.001 | 0.004  | 0.0    | 0.0    | nan   | 0.002 | 0.001 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.001 0.000 0.000 -1.000 0.000 0.000\n",
      "03/18 22:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0000  coco/Spruce_precision: 0.0010  coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0010  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0000  data_time: 0.5667  time: 2.9173\n",
      "03/18 22:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.0, bbox_mAP_50: 0.001, bbox_mAP_75: 0.0\n",
      "03/18 22:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_2/epoch_1.pth\n",
      "03/18 22:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_2/epoch_1.pth\n",
      "2025-03-18 22:13:00,480 - sual.inference.simdetector - INFO - 找到 97 张图片\n",
      "2025-03-18 22:13:00,480 - sual.inference.simdetector - INFO - 找到 97 张图片\n",
      "2025-03-18 22:13:00,480 - sual.inference.simdetector - INFO - 找到 97 张图片\n",
      "处理图片: 100%|█████████████████████████████████| 97/97 [00:10<00:00,  9.14it/s]\n",
      "2025-03-18 22:13:11,092 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:13:11,092 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:13:11,092 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 97/97 [00:49<00:00,  1.95it/s]\n",
      "2025-03-18 22:14:00,840 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_2/train_inference/20250318_221300/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:14:00,840 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_2/train_inference/20250318_221300/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:14:00,840 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_2/train_inference/20250318_221300/uncertainty/uncertainty_results.json\n",
      "03/18 22:14:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_2/train_stats.json\n",
      "03/18 22:14:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_2/epoch_1.pth\n",
      "03/18 22:14:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:14:02,063 - sual.inference.simdetector - INFO - 找到 1579 张图片\n",
      "2025-03-18 22:14:02,063 - sual.inference.simdetector - INFO - 找到 1579 张图片\n",
      "2025-03-18 22:14:02,063 - sual.inference.simdetector - INFO - 找到 1579 张图片\n",
      "2025-03-18 22:14:02,063 - sual.inference.simdetector - INFO - 找到 1579 张图片\n",
      "2025-03-18 22:14:02,063 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1579 张)\n",
      "2025-03-18 22:14:02,063 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1579 张)\n",
      "2025-03-18 22:14:02,063 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1579 张)\n",
      "2025-03-18 22:14:02,063 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1579 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:08<00:00,  2.26it/s]\n",
      "2025-03-18 22:14:10,909 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:14:10,909 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:14:10,909 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:14:10,909 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:10<00:00,  1.98it/s]\n",
      "2025-03-18 22:14:21,028 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_2/teacher_outputs/20250318_221402/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:14:21,028 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_2/teacher_outputs/20250318_221402/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:14:21,028 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_2/teacher_outputs/20250318_221402/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:14:21,028 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_2/teacher_outputs/20250318_221402/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 38.3071\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:14:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:14:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1649.8081\n",
      "03/18 22:14:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:14:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:14:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 2 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 107\n",
      "  - 未标注图片数: 1569\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 6.38%\n",
      "  - 已标注框数量: 6453\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0000\n",
      "  - bbox_mAP_50: 0.0010\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 3/16 轮主动学习...\n",
      "03/18 22:14:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_2/epoch_1.pth\n",
      "03/18 22:14:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_2/epoch_1.pth\n",
      "03/18 22:14:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1553459272\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1553459272\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:14:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_2/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_3'\n",
      "\n",
      "03/18 22:14:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:14:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_2/epoch_1.pth\n",
      "03/18 22:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_2/epoch_1.pth\n",
      "03/18 22:16:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_3.\n",
      "03/18 22:16:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/14]  lr: 2.0891e-04  eta: 0:00:06  time: 1.5254  data_time: 0.0968  memory: 6769  loss: 2.8848  loss_rpn_cls: 0.6594  loss_rpn_bbox: 0.3068  loss_cls: 0.9580  acc: 70.1172  loss_bbox: 0.9606\n",
      "03/18 22:16:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_221423\n",
      "03/18 22:16:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.43s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.016\n",
      "03/18 22:16:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.0   | 0.001  | 0.0    | 0.0    | nan   | 0.0   | 0.001 |\n",
      "| Spruce   | 0.003 | 0.015  | 0.0    | 0.0    | nan   | 0.002 | 0.004 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:16:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.003 0.000 0.000 -1.000 0.001 0.001\n",
      "03/18 22:16:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0000  coco/Spruce_precision: 0.0030  coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0030  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0010  coco/bbox_mAP_l: 0.0010  data_time: 0.6947  time: 2.6967\n",
      "03/18 22:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.44s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.016\n",
      "03/18 22:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.0   | 0.001  | 0.0    | 0.0    | nan   | 0.0   | 0.001 |\n",
      "| Spruce   | 0.003 | 0.015  | 0.0    | 0.0    | nan   | 0.002 | 0.004 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.003 0.000 0.000 -1.000 0.001 0.001\n",
      "03/18 22:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0000  coco/Spruce_precision: 0.0030  coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0030  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0010  coco/bbox_mAP_l: 0.0010  data_time: 0.5444  time: 2.5606\n",
      "03/18 22:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.0, bbox_mAP_50: 0.003, bbox_mAP_75: 0.0\n",
      "03/18 22:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_3/epoch_1.pth\n",
      "03/18 22:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_3/epoch_1.pth\n",
      "2025-03-18 22:16:43,061 - sual.inference.simdetector - INFO - 找到 107 张图片\n",
      "2025-03-18 22:16:43,061 - sual.inference.simdetector - INFO - 找到 107 张图片\n",
      "2025-03-18 22:16:43,061 - sual.inference.simdetector - INFO - 找到 107 张图片\n",
      "2025-03-18 22:16:43,061 - sual.inference.simdetector - INFO - 找到 107 张图片\n",
      "2025-03-18 22:16:43,061 - sual.inference.simdetector - INFO - 找到 107 张图片\n",
      "处理图片: 100%|███████████████████████████████| 107/107 [00:10<00:00, 10.04it/s]\n",
      "2025-03-18 22:16:53,724 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:16:53,724 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:16:53,724 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:16:53,724 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:16:53,724 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 107/107 [00:49<00:00,  2.17it/s]\n",
      "2025-03-18 22:17:42,926 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/train_inference/20250318_221643/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:17:42,926 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/train_inference/20250318_221643/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:17:42,926 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/train_inference/20250318_221643/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:17:42,926 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/train_inference/20250318_221643/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:17:42,926 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/train_inference/20250318_221643/uncertainty/uncertainty_results.json\n",
      "03/18 22:17:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_3/train_stats.json\n",
      "03/18 22:17:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_3/epoch_1.pth\n",
      "03/18 22:17:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:17:44,171 - sual.inference.simdetector - INFO - 找到 1569 张图片\n",
      "2025-03-18 22:17:44,171 - sual.inference.simdetector - INFO - 找到 1569 张图片\n",
      "2025-03-18 22:17:44,171 - sual.inference.simdetector - INFO - 找到 1569 张图片\n",
      "2025-03-18 22:17:44,171 - sual.inference.simdetector - INFO - 找到 1569 张图片\n",
      "2025-03-18 22:17:44,171 - sual.inference.simdetector - INFO - 找到 1569 张图片\n",
      "2025-03-18 22:17:44,171 - sual.inference.simdetector - INFO - 找到 1569 张图片\n",
      "2025-03-18 22:17:44,172 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1569 张)\n",
      "2025-03-18 22:17:44,172 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1569 张)\n",
      "2025-03-18 22:17:44,172 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1569 张)\n",
      "2025-03-18 22:17:44,172 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1569 张)\n",
      "2025-03-18 22:17:44,172 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1569 张)\n",
      "2025-03-18 22:17:44,172 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1569 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:09<00:00,  2.20it/s]\n",
      "2025-03-18 22:17:53,249 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:17:53,249 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:17:53,249 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:17:53,249 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:17:53,249 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:17:53,249 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:09<00:00,  2.20it/s]\n",
      "2025-03-18 22:18:02,352 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/teacher_outputs/20250318_221744/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:18:02,352 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/teacher_outputs/20250318_221744/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:18:02,352 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/teacher_outputs/20250318_221744/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:18:02,352 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/teacher_outputs/20250318_221744/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:18:02,352 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/teacher_outputs/20250318_221744/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:18:02,352 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_3/teacher_outputs/20250318_221744/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 20.4007\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:18:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:18:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -794.5428\n",
      "03/18 22:18:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:18:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:18:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 3 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 117\n",
      "  - 未标注图片数: 1559\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 6.98%\n",
      "  - 已标注框数量: 7130\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0000\n",
      "  - bbox_mAP_50: 0.0030\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 4/16 轮主动学习...\n",
      "03/18 22:18:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_3/epoch_1.pth\n",
      "03/18 22:18:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_3/epoch_1.pth\n",
      "03/18 22:18:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1992933770\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1992933770\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_3/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_4'\n",
      "\n",
      "03/18 22:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:19:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:19:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_3/epoch_1.pth\n",
      "03/18 22:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_3/epoch_1.pth\n",
      "03/18 22:19:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_4.\n",
      "03/18 22:20:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/15]  lr: 2.0891e-04  eta: 0:00:07  time: 1.5724  data_time: 0.1118  memory: 6778  loss: 2.8271  loss_rpn_cls: 0.6211  loss_rpn_bbox: 0.3045  loss_cls: 0.9158  acc: 71.3867  loss_bbox: 0.9857\n",
      "03/18 22:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_221804\n",
      "03/18 22:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:20:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.021\n",
      "03/18 22:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.005 | 0.015  | 0.001  | 0.0    | nan   | 0.0   | 0.005 |\n",
      "| Spruce   | 0.004 | 0.016  | 0.001  | 0.0    | nan   | 0.002 | 0.004 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.001 0.006 0.000 0.000 -1.000 0.001 0.002\n",
      "03/18 22:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0050  coco/Spruce_precision: 0.0040  coco/bbox_mAP: 0.0010  coco/bbox_mAP_50: 0.0060  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0010  coco/bbox_mAP_l: 0.0020  data_time: 0.7791  time: 2.9598\n",
      "03/18 22:20:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.021\n",
      "03/18 22:20:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.005 | 0.015  | 0.001  | 0.0    | nan   | 0.0   | 0.005 |\n",
      "| Spruce   | 0.004 | 0.016  | 0.001  | 0.0    | nan   | 0.002 | 0.004 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:20:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.001 0.006 0.000 0.000 -1.000 0.001 0.002\n",
      "03/18 22:20:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0050  coco/Spruce_precision: 0.0040  coco/bbox_mAP: 0.0010  coco/bbox_mAP_50: 0.0060  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0010  coco/bbox_mAP_l: 0.0020  data_time: 0.5989  time: 2.7489\n",
      "03/18 22:20:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.001, bbox_mAP_50: 0.006, bbox_mAP_75: 0.0\n",
      "03/18 22:20:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_4/epoch_1.pth\n",
      "03/18 22:20:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_4/epoch_1.pth\n",
      "2025-03-18 22:20:28,904 - sual.inference.simdetector - INFO - 找到 117 张图片\n",
      "2025-03-18 22:20:28,904 - sual.inference.simdetector - INFO - 找到 117 张图片\n",
      "2025-03-18 22:20:28,904 - sual.inference.simdetector - INFO - 找到 117 张图片\n",
      "2025-03-18 22:20:28,904 - sual.inference.simdetector - INFO - 找到 117 张图片\n",
      "2025-03-18 22:20:28,904 - sual.inference.simdetector - INFO - 找到 117 张图片\n",
      "2025-03-18 22:20:28,904 - sual.inference.simdetector - INFO - 找到 117 张图片\n",
      "2025-03-18 22:20:28,904 - sual.inference.simdetector - INFO - 找到 117 张图片\n",
      "处理图片: 100%|███████████████████████████████| 117/117 [00:12<00:00,  9.02it/s]\n",
      "2025-03-18 22:20:41,881 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:20:41,881 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:20:41,881 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:20:41,881 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:20:41,881 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:20:41,881 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:20:41,881 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 117/117 [00:57<00:00,  2.02it/s]\n",
      "2025-03-18 22:21:39,669 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/train_inference/20250318_222028/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:21:39,669 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/train_inference/20250318_222028/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:21:39,669 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/train_inference/20250318_222028/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:21:39,669 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/train_inference/20250318_222028/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:21:39,669 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/train_inference/20250318_222028/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:21:39,669 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/train_inference/20250318_222028/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:21:39,669 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/train_inference/20250318_222028/uncertainty/uncertainty_results.json\n",
      "03/18 22:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_4/train_stats.json\n",
      "03/18 22:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_4/epoch_1.pth\n",
      "03/18 22:21:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 找到 1559 张图片\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 找到 1559 张图片\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 找到 1559 张图片\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 找到 1559 张图片\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 找到 1559 张图片\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 找到 1559 张图片\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 找到 1559 张图片\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 找到 1559 张图片\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1559 张)\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1559 张)\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1559 张)\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1559 张)\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1559 张)\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1559 张)\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1559 张)\n",
      "2025-03-18 22:21:40,929 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1559 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:12<00:00,  1.57it/s]\n",
      "2025-03-18 22:21:53,673 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:21:53,673 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:21:53,673 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:21:53,673 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:21:53,673 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:21:53,673 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:21:53,673 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:21:53,673 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:09<00:00,  2.02it/s]\n",
      "2025-03-18 22:22:03,554 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/teacher_outputs/20250318_222140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:22:03,554 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/teacher_outputs/20250318_222140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:22:03,554 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/teacher_outputs/20250318_222140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:22:03,554 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/teacher_outputs/20250318_222140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:22:03,554 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/teacher_outputs/20250318_222140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:22:03,554 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/teacher_outputs/20250318_222140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:22:03,554 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/teacher_outputs/20250318_222140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:22:03,554 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_4/teacher_outputs/20250318_222140/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 21.4995\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -846.1009\n",
      "03/18 22:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 4 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 127\n",
      "  - 未标注图片数: 1549\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 7.58%\n",
      "  - 已标注框数量: 7751\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0010\n",
      "  - bbox_mAP_50: 0.0060\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 5/16 轮主动学习...\n",
      "03/18 22:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_4/epoch_1.pth\n",
      "03/18 22:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_4/epoch_1.pth\n",
      "03/18 22:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1384905983\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1384905983\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:22:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_4/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_5'\n",
      "\n",
      "03/18 22:22:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:22:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_4/epoch_1.pth\n",
      "03/18 22:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_4/epoch_1.pth\n",
      "03/18 22:23:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_5.\n",
      "03/18 22:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/16]  lr: 2.0891e-04  eta: 0:00:09  time: 1.6398  data_time: 0.1062  memory: 6777  loss: 2.7906  loss_rpn_cls: 0.5759  loss_rpn_bbox: 0.3046  loss_cls: 0.8958  acc: 70.2881  loss_bbox: 1.0143\n",
      "03/18 22:24:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_222205\n",
      "03/18 22:24:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.97s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.028\n",
      "03/18 22:24:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.003 | 0.009  | 0.001  | 0.0    | nan   | 0.0   | 0.003 |\n",
      "| Spruce   | 0.005 | 0.019  | 0.0    | 0.0    | nan   | 0.007 | 0.005 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:24:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.001 0.006 0.000 0.000 -1.000 0.002 0.002\n",
      "03/18 22:24:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0030  coco/Spruce_precision: 0.0050  coco/bbox_mAP: 0.0010  coco/bbox_mAP_50: 0.0060  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0020  coco/bbox_mAP_l: 0.0020  data_time: 0.7304  time: 2.8739\n",
      "03/18 22:24:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.95s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.028\n",
      "03/18 22:24:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.003 | 0.009  | 0.001  | 0.0    | nan   | 0.0   | 0.003 |\n",
      "| Spruce   | 0.005 | 0.019  | 0.0    | 0.0    | nan   | 0.007 | 0.005 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:24:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.001 0.006 0.000 0.000 -1.000 0.002 0.002\n",
      "03/18 22:24:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0030  coco/Spruce_precision: 0.0050  coco/bbox_mAP: 0.0010  coco/bbox_mAP_50: 0.0060  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0020  coco/bbox_mAP_l: 0.0020  data_time: 0.5675  time: 2.6119\n",
      "03/18 22:24:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.001, bbox_mAP_50: 0.006, bbox_mAP_75: 0.0\n",
      "03/18 22:24:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_5/epoch_1.pth\n",
      "03/18 22:24:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_5/epoch_1.pth\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "2025-03-18 22:24:32,275 - sual.inference.simdetector - INFO - 找到 127 张图片\n",
      "处理图片: 100%|███████████████████████████████| 127/127 [00:13<00:00,  9.11it/s]\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:24:46,215 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 127/127 [01:01<00:00,  2.06it/s]\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:25:47,894 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/train_inference/20250318_222432/uncertainty/uncertainty_results.json\n",
      "03/18 22:25:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_5/train_stats.json\n",
      "03/18 22:25:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_5/epoch_1.pth\n",
      "03/18 22:25:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,133 - sual.inference.simdetector - INFO - 找到 1549 张图片\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "2025-03-18 22:25:49,134 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1549 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:14<00:00,  1.34it/s]\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:26:04,067 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:09<00:00,  2.02it/s]\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:26:13,962 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_5/teacher_outputs/20250318_222549/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 25.2371\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1035.2618\n",
      "03/18 22:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 5 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 137\n",
      "  - 未标注图片数: 1539\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 8.17%\n",
      "  - 已标注框数量: 8179\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0010\n",
      "  - bbox_mAP_50: 0.0060\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 6/16 轮主动学习...\n",
      "03/18 22:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_5/epoch_1.pth\n",
      "03/18 22:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_5/epoch_1.pth\n",
      "03/18 22:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 588451669\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 588451669\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:26:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_5/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_6'\n",
      "\n",
      "03/18 22:26:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:26:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_5/epoch_1.pth\n",
      "03/18 22:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_5/epoch_1.pth\n",
      "03/18 22:28:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_6.\n",
      "03/18 22:28:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/18]  lr: 2.0891e-04  eta: 0:00:12  time: 1.5014  data_time: 0.0931  memory: 6771  loss: 2.6382  loss_rpn_cls: 0.4939  loss_rpn_bbox: 0.3051  loss_cls: 0.8480  acc: 70.1172  loss_bbox: 0.9912\n",
      "03/18 22:28:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_222616\n",
      "03/18 22:28:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:28:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.59s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.037\n",
      "03/18 22:28:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.002  | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.006 | 0.026  | 0.001  | 0.0    | nan   | 0.0   | 0.007 |\n",
      "| Spruce   | 0.006 | 0.026  | 0.002  | 0.0    | nan   | 0.013 | 0.007 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:28:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.011 0.000 0.000 -1.000 0.003 0.003\n",
      "03/18 22:28:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0060  coco/Spruce_precision: 0.0060  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0110  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0030  coco/bbox_mAP_l: 0.0030  data_time: 0.7097  time: 2.6880\n",
      "03/18 22:28:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.037\n",
      "03/18 22:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.002  | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.006 | 0.026  | 0.001  | 0.0    | nan   | 0.0   | 0.007 |\n",
      "| Spruce   | 0.006 | 0.026  | 0.002  | 0.0    | nan   | 0.013 | 0.007 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.011 0.000 0.000 -1.000 0.003 0.003\n",
      "03/18 22:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0060  coco/Spruce_precision: 0.0060  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0110  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0030  coco/bbox_mAP_l: 0.0030  data_time: 0.5410  time: 2.4301\n",
      "03/18 22:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.002, bbox_mAP_50: 0.011, bbox_mAP_75: 0.0\n",
      "03/18 22:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_6/epoch_1.pth\n",
      "03/18 22:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_6/epoch_1.pth\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "2025-03-18 22:28:40,274 - sual.inference.simdetector - INFO - 找到 137 张图片\n",
      "处理图片: 100%|███████████████████████████████| 137/137 [00:13<00:00,  9.81it/s]\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:28:54,245 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 137/137 [01:01<00:00,  2.24it/s]\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:29:55,362 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/train_inference/20250318_222840/uncertainty/uncertainty_results.json\n",
      "03/18 22:29:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_6/train_stats.json\n",
      "03/18 22:29:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_6/epoch_1.pth\n",
      "03/18 22:29:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 找到 1539 张图片\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "2025-03-18 22:29:56,543 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1539 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:17<00:00,  1.18it/s]\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:30:13,554 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:09<00:00,  2.20it/s]\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:30:22,652 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_6/teacher_outputs/20250318_222956/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 21.9299\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:30:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:30:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -889.1893\n",
      "03/18 22:30:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:30:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:30:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 6 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 147\n",
      "  - 未标注图片数: 1529\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 8.77%\n",
      "  - 已标注框数量: 8769\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0020\n",
      "  - bbox_mAP_50: 0.0110\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 7/16 轮主动学习...\n",
      "03/18 22:30:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_6/epoch_1.pth\n",
      "03/18 22:30:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_6/epoch_1.pth\n",
      "03/18 22:30:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 569006971\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 569006971\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:30:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_6/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_7'\n",
      "\n",
      "03/18 22:30:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:30:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_6/epoch_1.pth\n",
      "03/18 22:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_6/epoch_1.pth\n",
      "03/18 22:32:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_7.\n",
      "03/18 22:32:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/19]  lr: 2.0891e-04  eta: 0:00:13  time: 1.4549  data_time: 0.1135  memory: 6773  loss: 2.5699  loss_rpn_cls: 0.3929  loss_rpn_bbox: 0.3014  loss_cls: 0.8593  acc: 70.2637  loss_bbox: 1.0164\n",
      "03/18 22:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_223024\n",
      "03/18 22:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:32:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.68s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.041\n",
      "03/18 22:32:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.011 | 0.039  | 0.001  | 0.0    | nan   | 0.0   | 0.011 |\n",
      "| Spruce   | 0.008 | 0.03   | 0.001  | 0.0    | nan   | 0.0   | 0.009 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:32:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.014 0.000 0.000 -1.000 0.000 0.004\n",
      "03/18 22:32:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0110  coco/Spruce_precision: 0.0080  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0140  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0040  data_time: 0.7002  time: 2.5723\n",
      "03/18 22:32:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.59s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.041\n",
      "03/18 22:32:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.011 | 0.039  | 0.001  | 0.0    | nan   | 0.0   | 0.011 |\n",
      "| Spruce   | 0.008 | 0.03   | 0.001  | 0.0    | nan   | 0.0   | 0.009 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:32:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.014 0.000 0.000 -1.000 0.000 0.004\n",
      "03/18 22:32:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0000  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0110  coco/Spruce_precision: 0.0080  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0140  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0040  data_time: 0.5460  time: 2.4144\n",
      "03/18 22:32:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.002, bbox_mAP_50: 0.014, bbox_mAP_75: 0.0\n",
      "03/18 22:32:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_7/epoch_1.pth\n",
      "03/18 22:32:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_7/epoch_1.pth\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "2025-03-18 22:32:50,654 - sual.inference.simdetector - INFO - 找到 147 张图片\n",
      "处理图片: 100%|███████████████████████████████| 147/147 [00:15<00:00,  9.80it/s]\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:33:05,660 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 147/147 [01:05<00:00,  2.24it/s]\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:11,197 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/train_inference/20250318_223250/uncertainty/uncertainty_results.json\n",
      "03/18 22:34:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_7/train_stats.json\n",
      "03/18 22:34:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_7/epoch_1.pth\n",
      "03/18 22:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,640 - sual.inference.simdetector - INFO - 找到 1529 张图片\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "2025-03-18 22:34:12,641 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1529 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:15<00:00,  1.28it/s]\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:34:28,258 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:08<00:00,  2.23it/s]\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:34:37,235 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_7/teacher_outputs/20250318_223412/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 22.8917\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -922.9697\n",
      "03/18 22:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:34:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 7 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 157\n",
      "  - 未标注图片数: 1519\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 9.37%\n",
      "  - 已标注框数量: 9263\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0020\n",
      "  - bbox_mAP_50: 0.0140\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 8/16 轮主动学习...\n",
      "03/18 22:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_7/epoch_1.pth\n",
      "03/18 22:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_7/epoch_1.pth\n",
      "03/18 22:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1915110629\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1915110629\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_7/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_8'\n",
      "\n",
      "03/18 22:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_7/epoch_1.pth\n",
      "03/18 22:36:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_7/epoch_1.pth\n",
      "03/18 22:36:24 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:36:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_8.\n",
      "03/18 22:36:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/20]  lr: 2.0891e-04  eta: 0:00:15  time: 1.5252  data_time: 0.1024  memory: 6772  loss: 2.4994  loss_rpn_cls: 0.3926  loss_rpn_bbox: 0.2950  loss_cls: 0.8086  acc: 70.7031  loss_bbox: 1.0032\n",
      "03/18 22:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_223439\n",
      "03/18 22:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/20]  lr: 2.1881e-04  eta: 0:00:00  time: 1.5066  data_time: 0.0550  memory: 6769  loss: 2.4940  loss_rpn_cls: 0.3690  loss_rpn_bbox: 0.2988  loss_cls: 0.8061  acc: 74.1406  loss_bbox: 1.0201\n",
      "03/18 22:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:36:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.80s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.046\n",
      "03/18 22:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.001 | 0.006  | 0.0    | 0.0    | nan   | 0.0   | 0.002 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.008 | 0.028  | 0.0    | 0.0    | nan   | 0.0   | 0.008 |\n",
      "| Spruce   | 0.006 | 0.024  | 0.001  | 0.0    | nan   | 0.008 | 0.007 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.011 0.000 0.000 -1.000 0.002 0.003\n",
      "03/18 22:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0010  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0080  coco/Spruce_precision: 0.0060  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0110  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0020  coco/bbox_mAP_l: 0.0030  data_time: 0.7349  time: 2.8182\n",
      "03/18 22:37:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.73s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.046\n",
      "03/18 22:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.001 | 0.006  | 0.0    | 0.0    | nan   | 0.0   | 0.002 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.008 | 0.028  | 0.0    | 0.0    | nan   | 0.0   | 0.008 |\n",
      "| Spruce   | 0.006 | 0.024  | 0.001  | 0.0    | nan   | 0.008 | 0.007 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.011 0.000 0.000 -1.000 0.002 0.003\n",
      "03/18 22:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0010  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0080  coco/Spruce_precision: 0.0060  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0110  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0020  coco/bbox_mAP_l: 0.0030  data_time: 0.5715  time: 2.5754\n",
      "03/18 22:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.002, bbox_mAP_50: 0.011, bbox_mAP_75: 0.0\n",
      "03/18 22:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_8/epoch_1.pth\n",
      "03/18 22:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_8/epoch_1.pth\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "2025-03-18 22:37:09,464 - sual.inference.simdetector - INFO - 找到 157 张图片\n",
      "处理图片: 100%|███████████████████████████████| 157/157 [00:17<00:00,  9.05it/s]\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:37:26,823 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 157/157 [01:18<00:00,  2.01it/s]\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:38:45,042 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/train_inference/20250318_223709/uncertainty/uncertainty_results.json\n",
      "03/18 22:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_8/train_stats.json\n",
      "03/18 22:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_8/epoch_1.pth\n",
      "03/18 22:38:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 找到 1519 张图片\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "2025-03-18 22:38:46,691 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1519 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:19<00:00,  1.05it/s]\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:39:05,815 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:09<00:00,  2.00it/s]\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:39:15,797 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_8/teacher_outputs/20250318_223846/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 28.9021\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1183.7582\n",
      "03/18 22:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:39:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 8 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 167\n",
      "  - 未标注图片数: 1509\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 9.96%\n",
      "  - 已标注框数量: 10006\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0020\n",
      "  - bbox_mAP_50: 0.0110\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 9/16 轮主动学习...\n",
      "03/18 22:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_8/epoch_1.pth\n",
      "03/18 22:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_8/epoch_1.pth\n",
      "03/18 22:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1690555028\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1690555028\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_8/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_9'\n",
      "\n",
      "03/18 22:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:41:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:41:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_8/epoch_1.pth\n",
      "03/18 22:41:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_8/epoch_1.pth\n",
      "03/18 22:41:03 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:41:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_9.\n",
      "03/18 22:41:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/21]  lr: 2.0891e-04  eta: 0:00:18  time: 1.6617  data_time: 0.1022  memory: 6772  loss: 2.4846  loss_rpn_cls: 0.3546  loss_rpn_bbox: 0.2994  loss_cls: 0.7947  acc: 69.8730  loss_bbox: 1.0359\n",
      "03/18 22:41:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/21]  lr: 2.1881e-04  eta: 0:00:01  time: 1.6087  data_time: 0.0559  memory: 6769  loss: 2.4606  loss_rpn_cls: 0.3635  loss_rpn_bbox: 0.2961  loss_cls: 0.7720  acc: 71.6797  loss_bbox: 1.0290\n",
      "03/18 22:41:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_223918\n",
      "03/18 22:41:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.83s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.048\n",
      "03/18 22:41:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.002 | 0.006  | 0.0    | 0.0    | nan   | 0.0   | 0.002 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.004 | 0.019  | 0.0    | 0.0    | nan   | 0.0   | 0.004 |\n",
      "| Spruce   | 0.008 | 0.031  | 0.001  | 0.0    | nan   | 0.0   | 0.009 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:41:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.011 0.000 0.000 -1.000 0.000 0.003\n",
      "03/18 22:41:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0020  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0040  coco/Spruce_precision: 0.0080  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0110  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0030  data_time: 0.7332  time: 2.5712\n",
      "03/18 22:41:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.86s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.048\n",
      "03/18 22:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.002 | 0.006  | 0.0    | 0.0    | nan   | 0.0   | 0.002 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.004 | 0.019  | 0.0    | 0.0    | nan   | 0.0   | 0.004 |\n",
      "| Spruce   | 0.008 | 0.031  | 0.001  | 0.0    | nan   | 0.0   | 0.009 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.011 0.000 0.000 -1.000 0.000 0.003\n",
      "03/18 22:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0020  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0040  coco/Spruce_precision: 0.0080  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0110  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0030  data_time: 0.5700  time: 2.2380\n",
      "03/18 22:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.002, bbox_mAP_50: 0.011, bbox_mAP_75: 0.0\n",
      "03/18 22:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_9/epoch_1.pth\n",
      "03/18 22:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_9/epoch_1.pth\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "2025-03-18 22:41:52,271 - sual.inference.simdetector - INFO - 找到 167 张图片\n",
      "处理图片: 100%|███████████████████████████████| 167/167 [00:17<00:00,  9.55it/s]\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:42:09,766 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 167/167 [01:14<00:00,  2.23it/s]\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:24,649 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/train_inference/20250318_224152/uncertainty/uncertainty_results.json\n",
      "03/18 22:43:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_9/train_stats.json\n",
      "03/18 22:43:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_9/epoch_1.pth\n",
      "03/18 22:43:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,822 - sual.inference.simdetector - INFO - 找到 1509 张图片\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "2025-03-18 22:43:25,823 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1509 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:16<00:00,  1.25it/s]\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:43:41,845 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:08<00:00,  2.24it/s]\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:43:50,785 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_9/teacher_outputs/20250318_224325/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 30.3468\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:43:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:43:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1273.1189\n",
      "03/18 22:43:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:43:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 9 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 177\n",
      "  - 未标注图片数: 1499\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 10.56%\n",
      "  - 已标注框数量: 10536\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0020\n",
      "  - bbox_mAP_50: 0.0110\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 10/16 轮主动学习...\n",
      "03/18 22:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_9/epoch_1.pth\n",
      "03/18 22:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_9/epoch_1.pth\n",
      "03/18 22:43:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1136517329\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1136517329\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:43:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_9/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_10'\n",
      "\n",
      "03/18 22:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:45:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:45:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_9/epoch_1.pth\n",
      "03/18 22:45:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_9/epoch_1.pth\n",
      "03/18 22:45:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:45:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_10.\n",
      "03/18 22:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/23]  lr: 2.0891e-04  eta: 0:00:19  time: 1.5084  data_time: 0.1499  memory: 6768  loss: 2.4124  loss_rpn_cls: 0.3592  loss_rpn_bbox: 0.2930  loss_cls: 0.7460  acc: 70.4102  loss_bbox: 1.0142\n",
      "03/18 22:46:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/23]  lr: 2.1881e-04  eta: 0:00:04  time: 1.4312  data_time: 0.0787  memory: 6766  loss: 2.4175  loss_rpn_cls: 0.3491  loss_rpn_bbox: 0.2926  loss_cls: 0.7449  acc: 70.1904  loss_bbox: 1.0309\n",
      "03/18 22:46:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_224352\n",
      "03/18 22:46:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:46:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.67s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.050\n",
      "03/18 22:46:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.004 | 0.013  | 0.001  | 0.0    | nan   | 0.0   | 0.004 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.003 | 0.014  | 0.0    | 0.0    | nan   | 0.02  | 0.003 |\n",
      "| Spruce   | 0.01  | 0.034  | 0.003  | 0.0    | nan   | 0.0   | 0.011 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:46:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.012 0.001 0.000 -1.000 0.005 0.004\n",
      "03/18 22:46:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0040  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0030  coco/Spruce_precision: 0.0100  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0120  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0050  coco/bbox_mAP_l: 0.0040  data_time: 0.6811  time: 2.6524\n",
      "03/18 22:46:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.56s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.050\n",
      "03/18 22:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.004 | 0.013  | 0.001  | 0.0    | nan   | 0.0   | 0.004 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.003 | 0.014  | 0.0    | 0.0    | nan   | 0.02  | 0.003 |\n",
      "| Spruce   | 0.01  | 0.034  | 0.003  | 0.0    | nan   | 0.0   | 0.011 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.002 0.012 0.001 0.000 -1.000 0.005 0.004\n",
      "03/18 22:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0040  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0030  coco/Spruce_precision: 0.0100  coco/bbox_mAP: 0.0020  coco/bbox_mAP_50: 0.0120  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0050  coco/bbox_mAP_l: 0.0040  data_time: 0.5266  time: 2.3968\n",
      "03/18 22:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.002, bbox_mAP_50: 0.012, bbox_mAP_75: 0.001\n",
      "03/18 22:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_10/epoch_1.pth\n",
      "03/18 22:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_10/epoch_1.pth\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "2025-03-18 22:46:23,524 - sual.inference.simdetector - INFO - 找到 177 张图片\n",
      "处理图片: 100%|███████████████████████████████| 177/177 [00:18<00:00,  9.70it/s]\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:46:41,768 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 177/177 [01:20<00:00,  2.20it/s]\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:02,202 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/train_inference/20250318_224623/uncertainty/uncertainty_results.json\n",
      "03/18 22:48:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_10/train_stats.json\n",
      "03/18 22:48:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_10/epoch_1.pth\n",
      "03/18 22:48:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 找到 1499 张图片\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "2025-03-18 22:48:03,277 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1499 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:17<00:00,  1.15it/s]\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:48:20,715 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:10<00:00,  1.89it/s]\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:48:31,322 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_10/teacher_outputs/20250318_224803/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 31.5033\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1334.8384\n",
      "03/18 22:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 10 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 187\n",
      "  - 未标注图片数: 1489\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 11.16%\n",
      "  - 已标注框数量: 10979\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0020\n",
      "  - bbox_mAP_50: 0.0120\n",
      "  - bbox_mAP_75: 0.0010\n",
      "\n",
      "开始第 11/16 轮主动学习...\n",
      "03/18 22:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_10/epoch_1.pth\n",
      "03/18 22:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_10/epoch_1.pth\n",
      "03/18 22:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 666833182\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 666833182\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:48:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_10/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_11'\n",
      "\n",
      "03/18 22:48:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:48:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:50:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:50:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_10/epoch_1.pth\n",
      "03/18 22:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_10/epoch_1.pth\n",
      "03/18 22:50:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_11.\n",
      "03/18 22:50:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/24]  lr: 2.0891e-04  eta: 0:00:23  time: 1.6699  data_time: 0.1190  memory: 6766  loss: 2.4074  loss_rpn_cls: 0.3103  loss_rpn_bbox: 0.2886  loss_cls: 0.7482  acc: 70.2881  loss_bbox: 1.0603\n",
      "03/18 22:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/24]  lr: 2.1881e-04  eta: 0:00:06  time: 1.6193  data_time: 0.0638  memory: 6766  loss: 2.3904  loss_rpn_cls: 0.3250  loss_rpn_bbox: 0.2871  loss_cls: 0.7408  acc: 69.0186  loss_bbox: 1.0375\n",
      "03/18 22:50:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_224833\n",
      "03/18 22:50:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:51:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.92s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.057\n",
      "03/18 22:51:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.006 | 0.022  | 0.001  | 0.0    | nan   | 0.0   | 0.007 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.009 | 0.029  | 0.001  | 0.0    | nan   | 0.0   | 0.009 |\n",
      "| Spruce   | 0.009 | 0.034  | 0.001  | 0.0    | nan   | 0.0   | 0.011 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:51:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.004 0.017 0.001 0.000 -1.000 0.000 0.005\n",
      "03/18 22:51:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0060  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0090  coco/Spruce_precision: 0.0090  coco/bbox_mAP: 0.0040  coco/bbox_mAP_50: 0.0170  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0050  data_time: 0.7499  time: 2.7962\n",
      "03/18 22:51:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.93s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.057\n",
      "03/18 22:51:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.006 | 0.022  | 0.001  | 0.0    | nan   | 0.0   | 0.007 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.009 | 0.029  | 0.001  | 0.0    | nan   | 0.0   | 0.009 |\n",
      "| Spruce   | 0.009 | 0.034  | 0.001  | 0.0    | nan   | 0.0   | 0.011 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:51:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.004 0.017 0.001 0.000 -1.000 0.000 0.005\n",
      "03/18 22:51:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0060  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0090  coco/Spruce_precision: 0.0090  coco/bbox_mAP: 0.0040  coco/bbox_mAP_50: 0.0170  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0050  data_time: 0.5773  time: 2.6156\n",
      "03/18 22:51:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.004, bbox_mAP_50: 0.017, bbox_mAP_75: 0.001\n",
      "03/18 22:51:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_11/epoch_1.pth\n",
      "03/18 22:51:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_11/epoch_1.pth\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "2025-03-18 22:51:13,249 - sual.inference.simdetector - INFO - 找到 187 张图片\n",
      "处理图片: 100%|███████████████████████████████| 187/187 [00:21<00:00,  8.88it/s]\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:51:34,312 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 187/187 [01:34<00:00,  1.98it/s]\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:08,766 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/train_inference/20250318_225113/uncertainty/uncertainty_results.json\n",
      "03/18 22:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_11/train_stats.json\n",
      "03/18 22:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_11/epoch_1.pth\n",
      "03/18 22:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,076 - sual.inference.simdetector - INFO - 找到 1489 张图片\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "2025-03-18 22:53:10,077 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1489 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:19<00:00,  1.04it/s]\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:53:29,349 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:10<00:00,  1.99it/s]\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:53:39,425 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_11/teacher_outputs/20250318_225310/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 30.3169\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1279.4265\n",
      "03/18 22:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 11 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 197\n",
      "  - 未标注图片数: 1479\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 11.75%\n",
      "  - 已标注框数量: 11540\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0040\n",
      "  - bbox_mAP_50: 0.0170\n",
      "  - bbox_mAP_75: 0.0010\n",
      "\n",
      "开始第 12/16 轮主动学习...\n",
      "03/18 22:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_11/epoch_1.pth\n",
      "03/18 22:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_11/epoch_1.pth\n",
      "03/18 22:53:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 17450158\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 17450158\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:53:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_11/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_12'\n",
      "\n",
      "03/18 22:53:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:53:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:55:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 22:55:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_11/epoch_1.pth\n",
      "03/18 22:55:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_11/epoch_1.pth\n",
      "03/18 22:55:27 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 22:55:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_12.\n",
      "03/18 22:55:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/25]  lr: 2.0891e-04  eta: 0:00:23  time: 1.5743  data_time: 0.1083  memory: 6761  loss: 2.4048  loss_rpn_cls: 0.3255  loss_rpn_bbox: 0.2904  loss_cls: 0.7480  acc: 69.7266  loss_bbox: 1.0409\n",
      "03/18 22:55:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/25]  lr: 2.1881e-04  eta: 0:00:07  time: 1.5009  data_time: 0.0588  memory: 6771  loss: 2.3911  loss_rpn_cls: 0.3204  loss_rpn_bbox: 0.2882  loss_cls: 0.7369  acc: 69.9219  loss_bbox: 1.0456\n",
      "03/18 22:56:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_225341\n",
      "03/18 22:56:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 22:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.84s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.055\n",
      "03/18 22:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.005 | 0.018  | 0.0    | 0.0    | nan   | 0.0   | 0.005 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.007 | 0.027  | 0.001  | 0.0    | nan   | 0.0   | 0.007 |\n",
      "| Spruce   | 0.013 | 0.048  | 0.001  | 0.0    | nan   | 0.0   | 0.014 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.004 0.019 0.001 0.000 -1.000 0.000 0.005\n",
      "03/18 22:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0050  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0070  coco/Spruce_precision: 0.0130  coco/bbox_mAP: 0.0040  coco/bbox_mAP_50: 0.0190  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0050  data_time: 0.7127  time: 2.7833\n",
      "03/18 22:56:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.055\n",
      "03/18 22:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.005 | 0.018  | 0.0    | 0.0    | nan   | 0.0   | 0.005 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.007 | 0.027  | 0.001  | 0.0    | nan   | 0.0   | 0.007 |\n",
      "| Spruce   | 0.013 | 0.048  | 0.001  | 0.0    | nan   | 0.0   | 0.014 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 22:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.004 0.019 0.001 0.000 -1.000 0.000 0.005\n",
      "03/18 22:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0050  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0070  coco/Spruce_precision: 0.0130  coco/bbox_mAP: 0.0040  coco/bbox_mAP_50: 0.0190  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0050  data_time: 0.5550  time: 2.5866\n",
      "03/18 22:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.004, bbox_mAP_50: 0.019, bbox_mAP_75: 0.001\n",
      "03/18 22:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_12/epoch_1.pth\n",
      "03/18 22:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_12/epoch_1.pth\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "2025-03-18 22:56:19,624 - sual.inference.simdetector - INFO - 找到 197 张图片\n",
      "处理图片: 100%|███████████████████████████████| 197/197 [00:22<00:00,  8.59it/s]\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:56:42,556 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 197/197 [01:39<00:00,  1.98it/s]\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:22,271 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/train_inference/20250318_225619/uncertainty/uncertainty_results.json\n",
      "03/18 22:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_12/train_stats.json\n",
      "03/18 22:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_12/epoch_1.pth\n",
      "03/18 22:58:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,558 - sual.inference.simdetector - INFO - 找到 1479 张图片\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "2025-03-18 22:58:23,559 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1479 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:19<00:00,  1.01it/s]\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 22:58:43,281 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:10<00:00,  1.94it/s]\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "2025-03-18 22:58:53,618 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_12/teacher_outputs/20250318_225823/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 33.6526\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 22:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 22:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1443.6685\n",
      "03/18 22:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 22:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 22:58:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 12 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 207\n",
      "  - 未标注图片数: 1469\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 12.35%\n",
      "  - 已标注框数量: 12297\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0040\n",
      "  - bbox_mAP_50: 0.0190\n",
      "  - bbox_mAP_75: 0.0010\n",
      "\n",
      "开始第 13/16 轮主动学习...\n",
      "03/18 22:58:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_12/epoch_1.pth\n",
      "03/18 22:58:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_12/epoch_1.pth\n",
      "03/18 22:58:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1792818341\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1792818341\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 22:58:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_12/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_13'\n",
      "\n",
      "03/18 22:58:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 22:58:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 23:00:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 23:00:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_12/epoch_1.pth\n",
      "03/18 23:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_12/epoch_1.pth\n",
      "03/18 23:00:42 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 23:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_13.\n",
      "03/18 23:00:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/26]  lr: 2.0891e-04  eta: 0:00:27  time: 1.6883  data_time: 0.1132  memory: 6766  loss: 2.3761  loss_rpn_cls: 0.3212  loss_rpn_bbox: 0.2853  loss_cls: 0.7267  acc: 72.3633  loss_bbox: 1.0429\n",
      "03/18 23:01:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/26]  lr: 2.1881e-04  eta: 0:00:09  time: 1.6284  data_time: 0.0620  memory: 6759  loss: 2.3682  loss_rpn_cls: 0.3006  loss_rpn_bbox: 0.2861  loss_cls: 0.7278  acc: 72.8271  loss_bbox: 1.0536\n",
      "03/18 23:01:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_225856\n",
      "03/18 23:01:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 23:01:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.96s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.064\n",
      "03/18 23:01:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.007 | 0.029  | 0.003  | 0.0    | nan   | 0.0   | 0.008 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.006 | 0.023  | 0.001  | 0.0    | nan   | 0.033 | 0.006 |\n",
      "| Spruce   | 0.012 | 0.042  | 0.002  | 0.0    | nan   | 0.001 | 0.013 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 23:01:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.004 0.019 0.001 0.000 -1.000 0.008 0.005\n",
      "03/18 23:01:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0070  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0060  coco/Spruce_precision: 0.0120  coco/bbox_mAP: 0.0040  coco/bbox_mAP_50: 0.0190  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0080  coco/bbox_mAP_l: 0.0050  data_time: 0.7600  time: 2.9450\n",
      "03/18 23:01:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.064\n",
      "03/18 23:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.007 | 0.029  | 0.003  | 0.0    | nan   | 0.0   | 0.008 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.006 | 0.023  | 0.001  | 0.0    | nan   | 0.033 | 0.006 |\n",
      "| Spruce   | 0.012 | 0.042  | 0.002  | 0.0    | nan   | 0.001 | 0.013 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 23:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.004 0.019 0.001 0.000 -1.000 0.008 0.005\n",
      "03/18 23:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0070  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0060  coco/Spruce_precision: 0.0120  coco/bbox_mAP: 0.0040  coco/bbox_mAP_50: 0.0190  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0080  coco/bbox_mAP_l: 0.0050  data_time: 0.5851  time: 2.6772\n",
      "03/18 23:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.004, bbox_mAP_50: 0.019, bbox_mAP_75: 0.001\n",
      "03/18 23:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_13/epoch_1.pth\n",
      "03/18 23:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_13/epoch_1.pth\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "2025-03-18 23:01:40,454 - sual.inference.simdetector - INFO - 找到 207 张图片\n",
      "处理图片: 100%|███████████████████████████████| 207/207 [00:23<00:00,  8.71it/s]\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:02:04,210 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 207/207 [01:47<00:00,  1.92it/s]\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:03:51,994 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/train_inference/20250318_230140/uncertainty/uncertainty_results.json\n",
      "03/18 23:03:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_13/train_stats.json\n",
      "03/18 23:03:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_13/epoch_1.pth\n",
      "03/18 23:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,406 - sual.inference.simdetector - INFO - 找到 1469 张图片\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "2025-03-18 23:03:53,407 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1469 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:19<00:00,  1.01it/s]\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:04:13,177 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:10<00:00,  1.89it/s]\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:04:23,770 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_13/teacher_outputs/20250318_230353/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 31.6387\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 23:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 23:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1335.9001\n",
      "03/18 23:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 23:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 23:04:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 13 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 217\n",
      "  - 未标注图片数: 1459\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 12.95%\n",
      "  - 已标注框数量: 13059\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0040\n",
      "  - bbox_mAP_50: 0.0190\n",
      "  - bbox_mAP_75: 0.0010\n",
      "\n",
      "开始第 14/16 轮主动学习...\n",
      "03/18 23:04:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_13/epoch_1.pth\n",
      "03/18 23:04:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_13/epoch_1.pth\n",
      "03/18 23:04:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1852108952\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1852108952\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 23:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_13/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_14'\n",
      "\n",
      "03/18 23:04:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 23:04:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 23:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 23:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_13/epoch_1.pth\n",
      "03/18 23:06:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_13/epoch_1.pth\n",
      "03/18 23:06:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 23:06:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_14.\n",
      "03/18 23:06:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/28]  lr: 2.0891e-04  eta: 0:00:30  time: 1.6994  data_time: 0.1336  memory: 6757  loss: 2.3169  loss_rpn_cls: 0.3050  loss_rpn_bbox: 0.2818  loss_cls: 0.7026  acc: 70.5811  loss_bbox: 1.0275\n",
      "03/18 23:06:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/28]  lr: 2.1881e-04  eta: 0:00:13  time: 1.6289  data_time: 0.0727  memory: 6763  loss: 2.3375  loss_rpn_cls: 0.3045  loss_rpn_bbox: 0.2837  loss_cls: 0.7155  acc: 72.9004  loss_bbox: 1.0337\n",
      "03/18 23:06:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_230426\n",
      "03/18 23:06:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 23:07:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.067\n",
      "03/18 23:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.011 | 0.038  | 0.002  | 0.0    | nan   | 0.0   | 0.012 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.01  | 0.034  | 0.001  | 0.0    | nan   | 0.012 | 0.011 |\n",
      "| Spruce   | 0.016 | 0.055  | 0.002  | 0.0    | nan   | 0.0   | 0.018 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 23:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.006 0.025 0.001 0.000 -1.000 0.003 0.008\n",
      "03/18 23:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0110  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0100  coco/Spruce_precision: 0.0160  coco/bbox_mAP: 0.0060  coco/bbox_mAP_50: 0.0250  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0030  coco/bbox_mAP_l: 0.0080  data_time: 0.8343  time: 2.6674\n",
      "03/18 23:07:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.96s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.067\n",
      "03/18 23:07:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.011 | 0.038  | 0.002  | 0.0    | nan   | 0.0   | 0.012 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.01  | 0.034  | 0.001  | 0.0    | nan   | 0.012 | 0.011 |\n",
      "| Spruce   | 0.016 | 0.055  | 0.002  | 0.0    | nan   | 0.0   | 0.018 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 23:07:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.006 0.025 0.001 0.000 -1.000 0.003 0.008\n",
      "03/18 23:07:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0110  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0100  coco/Spruce_precision: 0.0160  coco/bbox_mAP: 0.0060  coco/bbox_mAP_50: 0.0250  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0030  coco/bbox_mAP_l: 0.0080  data_time: 0.6316  time: 2.3211\n",
      "03/18 23:07:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.006, bbox_mAP_50: 0.025, bbox_mAP_75: 0.001\n",
      "03/18 23:07:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_14/epoch_1.pth\n",
      "03/18 23:07:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_14/epoch_1.pth\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "2025-03-18 23:07:12,132 - sual.inference.simdetector - INFO - 找到 217 张图片\n",
      "处理图片: 100%|███████████████████████████████| 217/217 [00:25<00:00,  8.59it/s]\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:07:37,386 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 217/217 [01:50<00:00,  1.96it/s]\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:28,162 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/train_inference/20250318_230712/uncertainty/uncertainty_results.json\n",
      "03/18 23:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_14/train_stats.json\n",
      "03/18 23:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_14/epoch_1.pth\n",
      "03/18 23:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,459 - sual.inference.simdetector - INFO - 找到 1459 张图片\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "2025-03-18 23:09:29,461 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1459 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:17<00:00,  1.11it/s]\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:09:47,452 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:10<00:00,  1.88it/s]\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:09:58,107 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_14/teacher_outputs/20250318_230929/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 31.8451\n",
      "loading annotations into memory...\n",
      "Done (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 23:09:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 23:09:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1344.4044\n",
      "03/18 23:09:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 23:09:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 23:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 14 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 227\n",
      "  - 未标注图片数: 1449\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 13.54%\n",
      "  - 已标注框数量: 13618\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0060\n",
      "  - bbox_mAP_50: 0.0250\n",
      "  - bbox_mAP_75: 0.0010\n",
      "\n",
      "开始第 15/16 轮主动学习...\n",
      "03/18 23:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_14/epoch_1.pth\n",
      "03/18 23:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_14/epoch_1.pth\n",
      "03/18 23:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1725936580\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1725936580\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 23:10:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_14/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_15'\n",
      "\n",
      "03/18 23:10:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 23:10:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 23:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 23:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_14/epoch_1.pth\n",
      "03/18 23:11:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_14/epoch_1.pth\n",
      "03/18 23:11:46 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 23:11:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_15.\n",
      "03/18 23:12:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/29]  lr: 2.0891e-04  eta: 0:00:30  time: 1.5974  data_time: 0.1375  memory: 6757  loss: 2.3251  loss_rpn_cls: 0.2932  loss_rpn_bbox: 0.2823  loss_cls: 0.6982  acc: 73.8770  loss_bbox: 1.0514\n",
      "03/18 23:12:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/29]  lr: 2.1881e-04  eta: 0:00:13  time: 1.5337  data_time: 0.0744  memory: 6765  loss: 2.3225  loss_rpn_cls: 0.2973  loss_rpn_bbox: 0.2808  loss_cls: 0.7006  acc: 71.2646  loss_bbox: 1.0439\n",
      "03/18 23:12:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_231000\n",
      "03/18 23:12:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 23:12:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.055\n",
      "03/18 23:12:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.006 | 0.024  | 0.0    | 0.0    | nan   | 0.0   | 0.006 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.006 | 0.024  | 0.001  | 0.0    | nan   | 0.0   | 0.006 |\n",
      "| Spruce   | 0.01  | 0.043  | 0.001  | 0.0    | nan   | 0.002 | 0.011 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 23:12:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.003 0.018 0.000 0.000 -1.000 0.000 0.005\n",
      "03/18 23:12:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0060  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0060  coco/Spruce_precision: 0.0100  coco/bbox_mAP: 0.0030  coco/bbox_mAP_50: 0.0180  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0050  data_time: 0.8244  time: 2.6900\n",
      "03/18 23:12:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.055\n",
      "03/18 23:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.006 | 0.024  | 0.0    | 0.0    | nan   | 0.0   | 0.006 |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.006 | 0.024  | 0.001  | 0.0    | nan   | 0.0   | 0.006 |\n",
      "| Spruce   | 0.01  | 0.043  | 0.001  | 0.0    | nan   | 0.002 | 0.011 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 23:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.003 0.018 0.000 0.000 -1.000 0.000 0.005\n",
      "03/18 23:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0060  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0060  coco/Spruce_precision: 0.0100  coco/bbox_mAP: 0.0030  coco/bbox_mAP_50: 0.0180  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0050  data_time: 0.6040  time: 2.4381\n",
      "03/18 23:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.003, bbox_mAP_50: 0.018, bbox_mAP_75: 0.0\n",
      "03/18 23:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_15/epoch_1.pth\n",
      "03/18 23:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_15/epoch_1.pth\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "2025-03-18 23:12:46,150 - sual.inference.simdetector - INFO - 找到 227 张图片\n",
      "处理图片: 100%|███████████████████████████████| 227/227 [00:26<00:00,  8.61it/s]\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:13:12,531 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 227/227 [02:07<00:00,  1.77it/s]\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:20,467 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/train_inference/20250318_231246/uncertainty/uncertainty_results.json\n",
      "03/18 23:15:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_15/train_stats.json\n",
      "03/18 23:15:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_15/epoch_1.pth\n",
      "03/18 23:15:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,846 - sual.inference.simdetector - INFO - 找到 1449 张图片\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "2025-03-18 23:15:21,847 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1449 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:20<00:00,  1.01s/it]\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:15:42,145 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:11<00:00,  1.80it/s]\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:15:53,250 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_15/teacher_outputs/20250318_231521/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 35.7227\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 23:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 23:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1534.3380\n",
      "03/18 23:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 23:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 23:15:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 15 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 237\n",
      "  - 未标注图片数: 1439\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 14.14%\n",
      "  - 已标注框数量: 14235\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0030\n",
      "  - bbox_mAP_50: 0.0180\n",
      "  - bbox_mAP_75: 0.0000\n",
      "\n",
      "开始第 16/16 轮主动学习...\n",
      "03/18 23:15:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_15/epoch_1.pth\n",
      "03/18 23:15:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 加载上一轮检查点: work_dirs/al_ssc/round_15/epoch_1.pth\n",
      "03/18 23:15:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.20 (main, Oct  3 2024, 07:27:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 925590640\n",
      "    GPU 0: NVIDIA GeForce GTX 1080\n",
      "    CUDA_HOME: /usr/local/cuda-11.8\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 9.5.0-6ubuntu2) 9.5.0\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 925590640\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/18 23:15:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "active_learning = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_unlabeled.json',\n",
      "    data_prefix=dict(\n",
      "        img='data/ForestDamages/active_learning_ssc/images_unlabeled'),\n",
      "    data_root='data/ForestDamages/active_learning_ssc',\n",
      "    inference_options=dict(\n",
      "        sample_size=20,\n",
      "        score_thr=0.09,\n",
      "        selected_metric='ssc_score',\n",
      "        uncertainty_methods=[\n",
      "            'ssc',\n",
      "        ]),\n",
      "    max_iterations=16,\n",
      "    sample_selection=dict(num_samples=10, uncertainty_metric='ssc_score'))\n",
      "auto_scale_lr = dict(base_batch_size=4, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/ForestDamages/active_learning_ssc'\n",
      "dataset_type = 'ForestDamagesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "interval = 1\n",
      "load_from = 'work_dirs/al_ssc/round_15/epoch_1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 1\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'Aspen',\n",
      "        'Birch',\n",
      "        'Other',\n",
      "        'Pine',\n",
      "        'Spruce',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            142,\n",
      "        ),\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            230,\n",
      "        ),\n",
      "        (\n",
      "            106,\n",
      "            0,\n",
      "            228,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=5,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=300,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            score_thr=0.08),\n",
      "        rpn=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.3,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.2,\n",
      "                neg_iou_thr=0.2,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=3000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=20000, start_factor=0.01,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        by_epoch=True, gamma=0.1, milestones=[\n",
      "            350,\n",
      "            450,\n",
      "        ], type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2024.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2024/'),\n",
      "        data_root='data/ForestDamages',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ForestDamagesDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/ForestDamages/annotations/instances_val2024.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_train'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='ActiveCocoDataset'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        hue_delta=18,\n",
      "        saturation_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        min_crop_size=0.3,\n",
      "        min_ious=(\n",
      "            0.4,\n",
      "            0.5,\n",
      "            0.6,\n",
      "            0.7,\n",
      "        ),\n",
      "        type='MinIoURandomCrop'),\n",
      "    dict(angle_range=(\n",
      "        -10,\n",
      "        10,\n",
      "    ), type='RandomRotate'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    dataset=dict(\n",
      "        ann_file=\n",
      "        'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(\n",
      "            img='data/ForestDamages/active_learning_ssc/images_labeled_val'),\n",
      "        data_root='data/ForestDamages/active_learning_ssc',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'Aspen',\n",
      "                'Birch',\n",
      "                'Other',\n",
      "                'Pine',\n",
      "                'Spruce',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    142,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    230,\n",
      "                ),\n",
      "                (\n",
      "                    106,\n",
      "                    0,\n",
      "                    228,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='ActiveCocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/ForestDamages/active_learning_ssc/annotations/instances_labeled_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/al_ssc/round_16'\n",
      "\n",
      "03/18 23:15:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/18 23:15:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 23:17:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnext101_32x4d\n",
      "03/18 23:17:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_15/epoch_1.pth\n",
      "03/18 23:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/al_ssc/round_15/epoch_1.pth\n",
      "03/18 23:17:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/18 23:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /media/a1001/39330a0f-1025-4743-a3a2-199e9f2c5c00/code/mmdetection-3.1.0/work_dirs/al_ssc/round_16.\n",
      "03/18 23:17:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][10/30]  lr: 2.0891e-04  eta: 0:00:33  time: 1.6864  data_time: 0.1488  memory: 6760  loss: 2.3232  loss_rpn_cls: 0.3004  loss_rpn_bbox: 0.2880  loss_cls: 0.6989  acc: 69.9219  loss_bbox: 1.0359\n",
      "03/18 23:18:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][20/30]  lr: 2.1881e-04  eta: 0:00:16  time: 1.6129  data_time: 0.0794  memory: 6765  loss: 2.3146  loss_rpn_cls: 0.2996  loss_rpn_bbox: 0.2856  loss_cls: 0.7025  acc: 73.7793  loss_bbox: 1.0270\n",
      "03/18 23:18:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: al_faster-rcnn_sscmin_20250318_231555\n",
      "03/18 23:18:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][30/30]  lr: 2.2871e-04  eta: 0:00:00  time: 1.5757  data_time: 0.0552  memory: 6761  loss: 2.3368  loss_rpn_cls: 0.2999  loss_rpn_bbox: 0.2849  loss_cls: 0.7174  acc: 71.5234  loss_bbox: 1.0345\n",
      "03/18 23:18:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "03/18 23:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.068\n",
      "03/18 23:18:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.01  | 0.035  | 0.001  | 0.0    | nan   | 0.0   | 0.01  |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.012 | 0.045  | 0.003  | 0.0    | nan   | 0.001 | 0.013 |\n",
      "| Spruce   | 0.012 | 0.043  | 0.001  | 0.0    | nan   | 0.0   | 0.013 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 23:18:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.006 0.025 0.001 0.000 -1.000 0.000 0.007\n",
      "03/18 23:18:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0100  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0120  coco/Spruce_precision: 0.0120  coco/bbox_mAP: 0.0060  coco/bbox_mAP_50: 0.0250  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0070  data_time: 0.7485  time: 2.9536\n",
      "03/18 23:18:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.78s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.068\n",
      "03/18 23:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_95 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "| Aspen    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | nan   | 0.0   |\n",
      "| Birch    | 0.01  | 0.035  | 0.001  | 0.0    | nan   | 0.0   | 0.01  |\n",
      "| Other    | 0.0   | 0.0    | 0.0    | 0.0    | nan   | 0.0   | 0.0   |\n",
      "| Pine     | 0.012 | 0.045  | 0.003  | 0.0    | nan   | 0.001 | 0.013 |\n",
      "| Spruce   | 0.012 | 0.043  | 0.001  | 0.0    | nan   | 0.0   | 0.013 |\n",
      "+----------+-------+--------+--------+--------+-------+-------+-------+\n",
      "03/18 23:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.006 0.025 0.001 0.000 -1.000 0.000 0.007\n",
      "03/18 23:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/Aspen_precision: 0.0000  coco/Birch_precision: 0.0100  coco/Other_precision: 0.0000  coco/Pine_precision: 0.0120  coco/Spruce_precision: 0.0120  coco/bbox_mAP: 0.0060  coco/bbox_mAP_50: 0.0250  coco/bbox_mAP_75: 0.0010  coco/bbox_mAP_95: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0000  coco/bbox_mAP_l: 0.0070  data_time: 0.5805  time: 2.6994\n",
      "03/18 23:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 验证集评估结果: bbox_mAP: 0.006, bbox_mAP_50: 0.025, bbox_mAP_75: 0.001\n",
      "03/18 23:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 找到最佳检查点: work_dirs/al_ssc/round_16/epoch_1.pth\n",
      "03/18 23:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始对训练集进行推理...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_16/epoch_1.pth\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "2025-03-18 23:18:44,602 - sual.inference.simdetector - INFO - 找到 237 张图片\n",
      "处理图片: 100%|███████████████████████████████| 237/237 [00:27<00:00,  8.64it/s]\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:19:12,037 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|███████████████████████████| 237/237 [02:00<00:00,  1.97it/s]\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:12,414 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/train_inference/20250318_231844/uncertainty/uncertainty_results.json\n",
      "03/18 23:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 训练集统计信息已保存至: work_dirs/al_ssc/round_16/train_stats.json\n",
      "03/18 23:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始推理未标注数据...\n",
      "Loads checkpoint by local backend from path: work_dirs/al_ssc/round_16/epoch_1.pth\n",
      "03/18 23:21:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 未标注池中随机采样：20张\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,699 - sual.inference.simdetector - INFO - 找到 1439 张图片\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "2025-03-18 23:21:13,701 - sual.inference.simdetector - INFO - 采样 20 张图片进行推理 (总共 1439 张)\n",
      "处理图片: 100%|█████████████████████████████████| 20/20 [00:18<00:00,  1.05it/s]\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "2025-03-18 23:21:32,670 - sual.inference.simdetector - INFO - 开始计算不确定性...\n",
      "计算不确定性: 100%|█████████████████████████████| 20/20 [00:12<00:00,  1.62it/s]\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "2025-03-18 23:21:45,041 - sual.inference.simdetector - INFO - 不确定性结果已保存至: work_dirs/al_ssc/round_16/teacher_outputs/20250318_232113/uncertainty/uncertainty_results.json\n",
      "result_un 中的 ssc_score 平均值: 31.3192\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "03/18 23:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始选择新样本...\n",
      "03/18 23:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - sample_selection 参数: {'num_samples': 10, 'uncertainty_metric': 'ssc_score'}\n",
      "processed_results 中的 ssc_score 平均值: -1312.1047\n",
      "03/18 23:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 选择完成，选中样本数量: 10\n",
      "03/18 23:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 开始更新数据集...\n",
      "03/18 23:21:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - 数据集更新成功\n",
      "\n",
      "第 16 轮统计信息:\n",
      "数据集统计:\n",
      "  - 已标注图片数: 247\n",
      "  - 未标注图片数: 1429\n",
      "  - 总图片数: 1676\n",
      "  - 标注比例: 14.74%\n",
      "  - 已标注框数量: 14805\n",
      "验证集性能:\n",
      "  - bbox_mAP: 0.0060\n",
      "  - bbox_mAP_50: 0.0250\n",
      "  - bbox_mAP_75: 0.0010\n"
     ]
    }
   ],
   "source": [
    "!python sual/minal_train.py configs/al_config/al_config/al_faster-rcnn_sscmin.py --work-dir work_dirs/al_ssc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
